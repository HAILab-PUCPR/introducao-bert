{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifica√ß√£o com BERT\n",
    "\n",
    "Neste *notebook* voc√™ ver√° um exemplo de como usar o [BERT](https://arxiv.org/abs/1810.04805) para tarefa de classifica√ß√£o, usando Hugging Faces. \n",
    "\n",
    "Fontes:  \n",
    "\n",
    "- [BERT Fine-Tuning Tutorial with PyTorch](https://mccormickml.com/2019/07/22/BERT-fine-tuning/).\n",
    "- [Hugging Faces - Github](https://github.com/huggingface/transformers) e [Hugging Faces - site](https://huggingface.co/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro, vamos verificar se temos GPU dispon√≠vel para nossa execu√ß√£o. N√£o se preocupe caso n√£o possua GPU, apenas o treinamento ser√° mais demorado.\n",
    "\n",
    "Caso voc√™ esteja executando no Colab, acesse: Edit ü°í Notebook Settings ü°í Hardware accelerator ü°í (GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sem GPU dispon√≠vel, usando CPU.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Verificar se tem GPU dispon√≠vel\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Informa PyTorch para usar GPU\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('Existe(m)  %d GPU(s) dispon√≠vel(eis).' % torch.cuda.device_count())\n",
    "\n",
    "    print('Vamos usar a GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('Sem GPU dispon√≠vel, usando CPU.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biblioteca Transformers com *pytorch*\n",
    "\n",
    "Aqui vamos usar a interface *pytorch* porque possui um bom equil√≠brio entre as APIs de alto n√≠vel (f√°ceis de usar, mas sem fornecer informa√ß√µes sobre como as coisas funcionam) e c√≥digo de tensorflow (que cont√©m muitos detalhes, mas n√£o t√£o f√°ceis de usar).\n",
    "\n",
    "No momento, a biblioteca **Hugging Face** √© a interface *pytorch* mais utilizada para trabalhar com BERT. Al√©m de oferecer suporte a uma variedade de modelos pr√©-treinados, tamb√©m inclui modelos especifalizados para tarefas espec√≠ficas. Neste tutorial vamos usar *BertForSequenceClassification*.\n",
    "\n",
    "A biblioteca tamb√©m inclui classes espec√≠ficas de tarefas para classifica√ß√£o de *tokens*, resposta a perguntas (Q&A), previs√£o da pr√≥xima frase, etc. O uso dessas classes pr√©-constru√≠das simplifica o processo de modifica√ß√£o de BERT para nossos prop√≥sitos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# execute essa linha se estiver usando Colab\n",
    "#!pip install transformers\n",
    "!pip install transformers~=2.11.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Carregando o conjunto de dados (CoLA)\n",
    "\n",
    "Usaremos o conjunto de dados do *Corpus of Linguistic Acceptability (CoLA)* para a classifica√ß√£o de uma √∫nica frase. √â um conjunto de frases rotuladas como gramaticalmente corretas ou incorretas. Foi publicado pela primeira vez em maio de 2018, e √© um dos testes inclu√≠dos no ‚ÄúBenchmark GLUE‚Äù em que competem modelos como o BERT.\n",
    "\n",
    "Fa√ßa download do dataset neste link: https://nyu-mll.github.io/CoLA/ e descompacte o conjunto de dados na mesma pasta em que est√° trabalhando.\n",
    "\n",
    "Ou, se estiver no Colab, use o comando abaixo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usaremos o wget para baixar o conjunto de dados para o sistema de arquivos da inst√¢ncia Colab.\n",
    "!pip install wget\n",
    "\n",
    "import wget\n",
    "import os\n",
    "\n",
    "print('Baixando dataset...')\n",
    "\n",
    "# The URL for the dataset zip file.\n",
    "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
    "\n",
    "# Download the file (if we haven't already)\n",
    "if not os.path.exists('./cola_public_1.1.zip'):\n",
    "    wget.download(url, './cola_public_1.1.zip')\n",
    "    \n",
    "# Unzip the dataset (if we haven't already)\n",
    "if not os.path.exists('./cola_public/'):\n",
    "    !unzip cola_public_1.1.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### An√°lise\n",
    "\n",
    "Podemos ver pelos nomes dos arquivos que temos as vers√µes originais e as tokenizadas dos dados.\n",
    "\n",
    "N√£o vamos usar a vers√£o pr√©-tokenizada porque, para aplicar o nosso modelo BERT pr√©-treinado, devemos usar o tokenizer fornecido pelo modelo. Isso porque (1) o modelo tem um vocabul√°rio espec√≠fico e fixo e (2) o tokenizador BERT tem uma maneira particular de lidar com palavras fora do vocabul√°rio.\n",
    "\n",
    "Usaremos a biblioteca *pandas* para analisar o conjunto de treinamento e examinar algumas de suas propriedades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N√∫mero de senten√ßas de treinamento: 8,551\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_source</th>\n",
       "      <th>label</th>\n",
       "      <th>label_notes</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2471</th>\n",
       "      <td>l-93</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sarah sang.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6427</th>\n",
       "      <td>d_98</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All fugitives are in jail now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3936</th>\n",
       "      <td>ks08</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>John coughed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4404</th>\n",
       "      <td>ks08</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>There hopes to finish the project.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8284</th>\n",
       "      <td>ad03</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>Aphrodite wanted to live and Ishtar tried to do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5050</th>\n",
       "      <td>ks08</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>It surprised me that you came early.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4451</th>\n",
       "      <td>ks08</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In no other circumstances does that distinctio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2438</th>\n",
       "      <td>l-93</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The lax supervision was taken advantage of.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>cj99</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>The more obnoxious Fred, the less you should p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6097</th>\n",
       "      <td>c_13</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>John left his wife.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_source  label label_notes  \\\n",
       "2471            l-93      1         NaN   \n",
       "6427            d_98      1         NaN   \n",
       "3936            ks08      1         NaN   \n",
       "4404            ks08      0           *   \n",
       "8284            ad03      0           *   \n",
       "5050            ks08      1         NaN   \n",
       "4451            ks08      1         NaN   \n",
       "2438            l-93      1         NaN   \n",
       "173             cj99      0           *   \n",
       "6097            c_13      1         NaN   \n",
       "\n",
       "                                               sentence  \n",
       "2471                                        Sarah sang.  \n",
       "6427                     All fugitives are in jail now.  \n",
       "3936                                      John coughed.  \n",
       "4404                 There hopes to finish the project.  \n",
       "8284    Aphrodite wanted to live and Ishtar tried to do  \n",
       "5050               It surprised me that you came early.  \n",
       "4451  In no other circumstances does that distinctio...  \n",
       "2438        The lax supervision was taken advantage of.  \n",
       "173   The more obnoxious Fred, the less you should p...  \n",
       "6097                                John left his wife.  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset into a pandas dataframe.\n",
    "#df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "df = pd.read_csv(r\"C:\\Users\\lisat\\OneDrive\\cola_public_1.1\\cola_public\\raw\\in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "\n",
    "# Report the number of sentences.\n",
    "print('N√∫mero de senten√ßas de treinamento: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Display 10 random rows from the data.\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As duas propriedades com as quais realmente nos importamos s√£o as frases (*sentence*) e seus r√≥tulos (*label*), que podem ser 0 = incorreta, 1 = correta.\n",
    "\n",
    "Aqui est√£o cinco frases que s√£o rotuladas como incorretas (gramaticalmente). Observe como essa tarefa √© muito mais dif√≠cil do que algo como an√°lise de sentimento!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>Bill dried at the clothes.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4262</th>\n",
       "      <td>Seems John to fix the computer.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>I know a man who John is as tall as is.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669</th>\n",
       "      <td>John convinced that Bill has slept.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5643</th>\n",
       "      <td>The in loved peanut butter cookies.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     sentence  label\n",
       "3265               Bill dried at the clothes.      0\n",
       "4262          Seems John to fix the computer.      0\n",
       "1172  I know a man who John is as tall as is.      0\n",
       "7669      John convinced that Bill has slept.      0\n",
       "5643      The in loved peanut butter cookies.      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df.label == 0].sample(5)[['sentence', 'label']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos extrair as frases e seus r√≥tulos do nosso corpus de treinamento como *numpy ndarrays*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Lista de senten√ßas e seus r√≥tulos\n",
    "sentences = df.sentence.values\n",
    "labels = df.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Tokeniza√ß√£o\n",
    "\n",
    "Agora vamos transformar nosso conjunto de dados no formato em que o BERT pode ser treinado.\n",
    "\n",
    "Para alimentar o BERT com nosso texto, ele deve ser dividido em *tokens* e, em seguida, esses *tokens* devem ser mapeados para seu √≠ndice no vocabul√°rio do tokenizador.\n",
    "\n",
    "A tokeniza√ß√£o deve ser realizada pelo tokenizador inclu√≠do no modelo BERT que estamos trabalhando, que vamos baixar no c√≥digo abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando tokenizador BERT...\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Carregar o tokenizador BERT.\n",
    "print('Carregando tokenizador BERT...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Vamos aplicar o tokenizer a uma frase apenas para ver a sa√≠da."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
      "Tokenizada:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
      "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
     ]
    }
   ],
   "source": [
    "# Frase original\n",
    "print(' Original: ', sentences[0])\n",
    "\n",
    "# Frase dividida em tokens\n",
    "print('Tokenizada: ', tokenizer.tokenize(sentences[0]))\n",
    "\n",
    "# Senten√ßa mapeada em token ids\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Quando realmente convertermos todas as nossas senten√ßas, usaremos a fun√ß√£o ¬¥¬¥¬¥tokenize.encode¬¥¬¥¬¥ para lidar com ambas as etapas, em vez de chamar as fun√ß√µes que usamos acima separadamente.\n",
    "\n",
    "Antes de fazermos isso, precisamos falar sobre alguns dos requisitos de formata√ß√£o do BERT.\n",
    "\n",
    "### Formata√ß√£o\n",
    "\n",
    "O c√≥digo acima omitiu algumas etapas de formata√ß√£o necess√°rias que veremos aqui.\n",
    "\n",
    "Precisamos:\n",
    "1. Adicione *tokens* especiais no in√≠cio e fim de cada frase.\n",
    "2. Agrupar e truncar todas as frases para terem o mesmo comprimento.\n",
    "3. Diferenciar explicitamente *tokens* reais de *tokens* de preenchimento com a ‚Äúm√°scara de aten√ß√£o‚Äù.\n",
    "\n",
    "**Tokens especiais**\n",
    "[SEP] - No final de cada frase, precisamos acrescentar o token especial [SEP], que √© usado em tarefas de duas senten√ßas, onde BERT recebe duas senten√ßas separadas e √© solicitado a determinar algo (por exemplo, a resposta √† pergunta na senten√ßa A pode ser encontrada na senten√ßa B).\n",
    "\n",
    "[CLS] - Para tarefas de classifica√ß√£o, devemos acrescentar o [CLS] ao in√≠cio de cada frase. Como o BERT consiste em 12 camadas de Tranformer, cada uma recebe uma lista de *embeddings* e produz o mesmo n√∫mero de *embeddings* na sa√≠da (com outros valores), na sa√≠da do transformador final (12¬∫), apenas o primeiro *embedding* (correspondente ao *token* [CLS]) √© usado pelo classificador .\n",
    "\n",
    "‚ÄúO primeiro *token* de cada sequ√™ncia √© sempre um *token* de classifica√ß√£o especial ([CLS]), onde o estado oculto final deste *token* √© usado como a representa√ß√£o da sequ√™ncia agregada para tarefas de classifica√ß√£o.‚Äù (do artigo BERT)\n",
    "\n",
    "N√£o precisamos pensar em estrat√©gias de *pool* sobre os *embeddings* finais, pois nesse token [CLS] de classifica√ß√£o, o modelo codificou tudo o que precisamos para a classifica√ß√£o naquele √∫nico vetor de incorpora√ß√£o de 768 valores. J√° est√° feito o *pool* para n√≥s!\n",
    "\n",
    "*Comprimento da frase e m√°scara de aten√ß√£o*\n",
    "\n",
    "As senten√ßas em nosso conjunto de dados obviamente t√™m comprimentos variados, ent√£o como o BERT lida com isso?\n",
    "\n",
    "BERT tem duas restri√ß√µes:\n",
    "\n",
    "- Todas as frases devem ser preenchidas ou truncadas em um √∫nico comprimento fixo.\n",
    "- O comprimento m√°ximo da frase √© 512 *tokens*.\n",
    "\n",
    "O preenchimento √© feito com um *token* especial [PAD], que est√° no √≠ndice 0 no vocabul√°rio BERT.\n",
    "\n",
    "A ‚ÄúM√°scara de Aten√ß√£o‚Äù √© simplesmente uma matriz de 1s e 0s indicando quais *tokens* est√£o preenchendo e quais n√£o est√£o (parece meio redundante, n√£o √© ?). Essa m√°scara diz ao mecanismo de ‚ÄúAutoaten√ß√£o‚Äù do BERT para n√£o incorporar esses *tokens* (PAD) em sua interpreta√ß√£o da frase.\n",
    "\n",
    "O comprimento m√°ximo afeta a velocidade de treinamento e avalia√ß√£o. Por exemplo, com um Tesla K80:\n",
    "\n",
    "MAX_LEN = 128 --> Cada √©poca leva ~5:28 para treinar\n",
    "\n",
    "MAX_LEN = 64 --> Cada √©poca leva ~2:57 para treinar\n",
    "\n",
    "**Tokenizar o conjunto de dados**\n",
    "\n",
    "A biblioteca Transformers fornece uma fun√ß√£o ¬¥¬¥¬¥encode¬¥¬¥¬¥ √∫til que tratar√° da maioria das etapas de an√°lise e prepara√ß√£o de dados para n√≥s.\n",
    "\n",
    "Antes de estarmos prontos para codificar nosso texto, no entanto, precisamos decidir sobre o comprimento m√°ximo de frase para preenchimento ou truncamento.\n",
    "\n",
    "A c√©lula abaixo realizar√° uma passagem de tokeniza√ß√£o do conjunto de dados para medir o comprimento m√°ximo da frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase com tamanho m√°ximo:  47\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "\n",
    "# Para cada frase\n",
    "for sent in sentences:\n",
    "\n",
    "    # Tokeniza o texti e adiciona os tokens `[CLS]` e `[SEP]`\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "    # Atualiza o comprimento m√°ximo da frase\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Frase com tamanho m√°ximo: ', max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Para o caso de haver algumas senten√ßas mais longas no conjunto de teste, o comprimento m√°ximo ser√° de 64.\n",
    "\n",
    "Agora estamos prontos para realizar a tokeniza√ß√£o.\n",
    "\n",
    "A fun√ß√£o ¬¥¬¥¬¥tokenizer.encode_plus¬¥¬¥¬¥ realiza v√°rias etapas para n√≥s:\n",
    "\n",
    "1. Divide a frase em *tokens*.\n",
    "2. Adiciona os *tokens* especiais [CLS] e [SEP].\n",
    "3. Mapeia os *tokens* para seus IDs.\n",
    "4. Preenche ou trunca todas as frases com o mesmo comprimento.\n",
    "5. Cria as m√°scaras de aten√ß√£o que diferenciam explicitamente *tokens* reais de *tokens* [PAD].\n",
    "\n",
    "As primeiras quatro etapas s√£o realizadas pela fun√ß√£o ¬¥¬¥¬¥tokenizer.encode¬¥¬¥¬¥, mas vamos usar a ¬¥¬¥¬¥tokenizer.encode_plus¬¥¬¥¬¥ para a quinta etapa (m√°scaras de aten√ß√£o). [Documenta√ß√£o aqui](https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\lisat\\anaconda3\\envs\\torch\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
      "Token IDs: tensor([  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n",
      "         2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "# Tokeniza todas as frases e mapeia os tokens em seus IDs\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# Para cada frase\n",
    "for sent in sentences:\n",
    "    # `encode_plus` far√° o seguinte:\n",
    "    #   (1) Tokeniza a frase\n",
    "    #   (2) Adiciona o token `[CLS]` no inicio\n",
    "    #   (3) Adiciona o token `[SEP]` no final\n",
    "    #   (4) Mapeia os tokens em seus IDs.\n",
    "    #   (5) Adiciona preenchimento (pad) ou trunca a frase at√° o comprimento m√°ximo (`max_length`)\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Frase a ser codificada\n",
    "                        add_special_tokens = True, # Adiciona '[CLS]' e '[SEP]'\n",
    "                        max_length = 64,           # Preenche & trunca todas as frases\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Constr√≥i m√°scaras de aten√ß√£o\n",
    "                        return_tensors = 'pt',     # Returna tensores pytorch.\n",
    "                   )\n",
    "    \n",
    "    # Adiciona a frase codificada na lista\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # E sua m√°scara de aten√ß√£o (simplesmente diferencia tokens reais de tokens de preenchimento - PAD).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Converte a lista em tensores\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Imprime frase 0, agora como uma lista de IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Divis√£o dos dados - treinamento e valida√ß√£o\n",
    "\n",
    "Precisamos agora dividir nosso conjunto de treinamento, em 90% para treinamento e 10% para valida√ß√£o.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7,695 isnt√¢ncias de treinamento\n",
      "  856 inst√¢ncias de valida√ß√£o\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combina as entradas de treinamento em um TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Criar uma divis√£o 90-10 para treinamento-valida√ß√£o.\n",
    "\n",
    "# Calcula o n√∫mero de inst√¢ncias para incluir em cada divis√£o\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide o dataset pegando randomicamente as inst√¢ncia \n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} isnt√¢ncias de treinamento'.format(train_size))\n",
    "print('{:>5,} inst√¢ncias de valida√ß√£o'.format(val_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar um iterador para nosso conjunto de dados usando a classe DataLoader, para economizar mem√≥ria durante o treinamento, visto que, ao contr√°rio de um *loop* com *for*, com o iterador o conjunto de dados inteiro n√£o precisa ser carregado na mem√≥ria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# O DataLoader precisa saber no tamanho do batch size para treinamento, ent√£o vamos espeficiar\n",
    "# Para o fine-tuning em uma tarefa, os autores recomendam um batch size de 16 ou 32.\n",
    "batch_size = 16\n",
    "\n",
    "# Criar os DataLoaders para nossos conjuntos de treinamento e teste\n",
    "# Vamos pegar inst√¢ncias de treinamento em ordem aleat√≥ria\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # Exemplos de treinamento\n",
    "            sampler = RandomSampler(train_dataset), # Seleciona batches aleatoriamente\n",
    "            batch_size = batch_size # Treina com este batch size.\n",
    "        )\n",
    "\n",
    "# Para valida√ß√£o, a ordem n√£o importa, ent√£o vamos mant√™-la sequencial\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # Exemplos de valida√ß√£o.\n",
    "            sampler = SequentialSampler(val_dataset), # Execita os batches sequencialmente.\n",
    "            batch_size = batch_size # Avalia com este batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de classifica√ß√£o##\n",
    "\n",
    "Agora que nossos dados de entrada est√£o formatados corretamente, √© hora de ajustar o modelo de BERT.\n",
    "\n",
    "### BertForSequenceClassification\n",
    "\n",
    "Para a tarefa de classifica√ß√£o, vamos modificar o modelo BERT pr√©-treinado para fornecer sa√≠das para classifica√ß√£o e, em seguida, treinar todo modelo em nosso conjunto de dados at√© que esteja especializado para nossa tarefa.\n",
    "\n",
    "Felizmente, a implementa√ß√£o do Hugging Face *pytorch* inclui um conjunto de interfaces projetadas para uma variedade de tarefas de PLN. Embora essas interfaces sejam todas constru√≠das em cima de um modelo BERT treinado, cada uma tem diferentes camadas superiores e tipos de sa√≠da projetados para nossa tarefa PNL espec√≠fica.\n",
    "\n",
    "Aqui est√° a lista atual de classes fornecidas para a especializa√ß√£o da tarefa (ajuste fino ou *fine tuning*):\n",
    "\n",
    "1. BertModel\n",
    "1. BertForPreTraining\n",
    "1. BertForMaskedLM\n",
    "1. BertForNextSentencePrediction\n",
    "1. BertForSequenceClassification (**usaremos aqui**)\n",
    "1. BertForTokenClassification\n",
    "1. BertForQuestionAnswering\n",
    "\n",
    "A documenta√ß√£o para eles pode ser encontrada [aqui](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html).\n",
    "\n",
    "Estaremos usando *BertForSequenceClassification*, modelo BERT com uma camada linear √∫nica adicionada no topo para classifica√ß√£o, que ser√° usado como um classificador de frases. √Ä medida que alimentamos os dados de entrada, todo o modelo BERT pr√©-treinado e a camada adicional de classifica√ß√£o n√£o treinada ser√£o treinados em nossa tarefa espec√≠fica.\n",
    "\n",
    "OK, vamos carregar o BERT! Existem alguns modelos diferentes de BERT pr√©-treinados dispon√≠veis. ‚Äúbert-base-uncased‚Äù significa a vers√£o que tem apenas letras min√∫sculas (‚Äúsem caixa‚Äù) e √© a vers√£o menor das duas (‚Äúbase‚Äù vs ‚Äúlarge‚Äù).\n",
    "\n",
    "A documenta√ß√£o do m√©todo ```from_pretrained``` pode ser encontrada [aqui](https://huggingface.co/transformers/v2.2.0/main_classes/model.html#transformers.PreTrainedModel.from_pretrained), com os par√¢metros adicionais definidos [aqui](https://huggingface.co/transformers/v2.2.0/main_classes/configuration.html#transformers.PretrainedConfig)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Carrega a classe BertForSequenceClassification, o modelo pre-treinado com uma camada linear simples no topo\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Usa o BERT com 12 camadas, com vocabulario com caixa baixa\n",
    "    num_labels = 2, # O n√∫mero de sa√≠das, ou r√≥tulos, do nosso modelo (classifica√ß√£o bin√°ria em nosso caso)\n",
    "                    # Para tarefas com mais classes (multi-classe), podemos aumentar esse n√∫mero\n",
    "    output_attentions = False, # Se o modelo deve retornar os pesos de aten√ß√£o\n",
    "    output_hidden_states = False, # Se o modelo deve retornar todos estados escondidos\n",
    ")\n",
    "\n",
    "# Se voc√™ tem GPU, configura o pytorch para executar o modelo na GPU\n",
    "#model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apenas por curiosidade, podemos navegar por todos os par√¢metros do modelo.\n",
    "\n",
    "Na c√©lula abaixo, imprimimos os nomes e dimens√µes dos pesos para:\n",
    "\n",
    "1. A camada de incorpora√ß√£o.\n",
    "1. O primeiro dos doze transformadores.\n",
    "1. A camada de sa√≠da."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O modelo BERT tem 201 par√¢metros diferentes.\n",
      "\n",
      "==== Camada de incorpora√ß√£o (Embedding) ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== Primeiro Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Camada de Sa√≠da ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "# Lista todos os paremtros do modelo como uma lista de tuplas\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('O modelo BERT tem {:} par√¢metros diferentes.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Camada de incorpora√ß√£o (Embedding) ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Primeiro Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Camada de Sa√≠da ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otimizador e taxas de aprendizagem ##\n",
    "\n",
    "Agora que carregamos nosso modelo, precisamos pegar os hiperpar√¢metros de treinamento de dentro do modelo armazenado.\n",
    "\n",
    "Para fins de ajuste fino, os autores recomendam escolher entre os seguintes valores (do Ap√™ndice A.3 do artigo de BERT ):\n",
    "\n",
    "1. Tamanho do lote (*batch size*): 16, 32\n",
    "1. Taxa de aprendizagem (*Adam*): 5e-5, 3e-5, 2e-5\n",
    "1. N√∫mero de √©pocas: 2, 3, 4\n",
    "\n",
    "Aqui vamos usar:\n",
    "\n",
    "1. Tamanho do lote: 16 (definido ao criar nossos *DataLoaders*)\n",
    "1. Taxa de aprendizagem: 2e-5\n",
    "1. √âpocas: 4 (veremos que provavelmente s√£o muitas ...)\n",
    "\n",
    "O par√¢metro ```eps = 1e-8``` √© ‚Äúum n√∫mero muito pequeno para evitar qualquer divis√£o por zero na implementa√ß√£o‚Äù (leia mais [aqui](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
    "\n",
    "Voc√™ pode encontrar a cria√ß√£o do otimizador *AdamW* em ```run_glue.py``` [aqui](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nota: AdamW √© uma classe da biblioteca huggingface\n",
    "# Provavelmente o 'W' √© de 'Weight Decay fix\" ('Corre√ß√£o de redu√ß√£o de peso \")\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - o padr√£o √©  5e-5, aqui usamos 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - o padr√£o √© 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# N√∫mero de √©pocas de treinamento. Os autores do BERT recomendam entre 2 a 4. \n",
    "# N√≥s escolhemos 4, mas vamos ver depois que isso pode estar causando overfit nos dados de treinamento\n",
    "epochs = 4\n",
    "\n",
    "# N√∫mero total de passos de treinamento √© [n√∫mero de batches] x [n√∫mero de √©pocas]. \n",
    "# (Note que n√£o √© o mesmo que o n√∫mero de inst√¢ncias de treinamento).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Criando o programador de taxa de aprendizagem (learning rate scheduler.)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Valor padr√£o no run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Loop* de treinamento ##\n",
    "\n",
    "Abaixo est√° o nosso *loop* de treinamento. H√° muita coisa acontecendo, mas fundamentalmente para cada passagem em nosso *loop*, temos uma fase de treinamento e uma fase de valida√ß√£o.\n",
    "\n",
    "**Treinamento:**\n",
    "\n",
    "1. Descompacta nossas entradas (dados e r√≥tulos)\n",
    "1. Carrega dados na GPU para acelera√ß√£o (quando necess√°rio)\n",
    "1. Limpa os gradientes calculados na passagem anterior.\n",
    "(No *pytorch*, os gradientes se acumulam por padr√£o (√∫til para coisas como RNNs), a menos que a gente limpe explicitamente)\n",
    "1. Passo *Forward* (avan√ßo), alimentando os dados de entrada pela rede\n",
    "1. Passo *Backward* (para tr√°s), ou retropropaga√ß√£o\n",
    "1. Informa a rede para atualizar os par√¢metros com ```optimizer.step ()```\n",
    "1. Rastreia vari√°veis para monitorar o progresso\n",
    "\n",
    "**Avalia√ß√£o:**\n",
    "\n",
    "1. Descompacta nossas entradas (dados e r√≥tulos)\n",
    "1. Carrega dados na GPU para acelera√ß√£o (quando necess√°rio)\n",
    "1. Passo *Forward* (avan√ßo), alimentando os dados de entrada pela rede\n",
    "1. Calcula a perda (*loss*) em nossos dados de valida√ß√£o e rastreie vari√°veis para monitorar o progresso\n",
    "\n",
    "*Pytorch* esconde todos os c√°lculos detalhados, mas comentamos o c√≥digo para apontar quais das etapas acima est√£o acontecendo em cada linha.\n",
    "\n",
    "No c√≥digo abaixo, definimos uma fun√ß√£o auxiliar para calcular a precis√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Fun√ß√£o para caluclar a acur√°cia das nossas perdi√ß√µes x r√≥tulos\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fun√ß√£o auxiliar para formatar o tempo decorrido (hh:mm:ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Pega o tempo em segundos e retorna como hh:mm:ss\n",
    "    '''\n",
    "    # Arredonda\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Formata como hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos prontos para come√ßar o treinamento!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
            "======== √âpoca 1 / 4 ========\n",
            "Treinando...\n",
            "  Batch    40  de    241.    Tempo: 0:00:09.\n",
            "  Batch    80  de    241.    Tempo: 0:00:18.\n",
            "  Batch   120  de    241.    Tempo: 0:00:26.\n",
            "  Batch   160  de    241.    Tempo: 0:00:35.\n",
            "  Batch   200  de    241.    Tempo: 0:00:44.\n",
            "  Batch   240  de    241.    Tempo: 0:00:52.\n",
            "\n",
            "  Perda m√©dia do treinamento: 0.09\n",
            "  √©poca de treinamento levou : 0:00:53\n",
            "\n",
            "Executando Valida√ß√£o...\n",
            "  Acur√°cia: 0.81\n",
            "  Valida√ß√£o perda (Loss): 0.63\n",
            "  Valida√ß√£o levou: 0:00:02\n",
            "\n",
            "======== √âpoca 2 / 4 ========\n",
            "Treinando...\n",
            "  Batch    40  de    241.    Tempo: 0:00:09.\n",
            "  Batch    80  de    241.    Tempo: 0:00:17.\n",
            "  Batch   120  de    241.    Tempo: 0:00:26.\n",
            "  Batch   160  de    241.    Tempo: 0:00:35.\n",
            "  Batch   200  de    241.    Tempo: 0:00:43.\n",
            "  Batch   240  de    241.    Tempo: 0:00:52.\n",
            "\n",
            "  Perda m√©dia do treinamento: 0.08\n",
            "  √©poca de treinamento levou : 0:00:52\n",
            "\n",
            "Executando Valida√ß√£o...\n",
            "  Acur√°cia: 0.81\n",
            "  Valida√ß√£o perda (Loss): 0.63\n",
            "  Valida√ß√£o levou: 0:00:02\n",
            "\n",
            "======== √âpoca 3 / 4 ========\n",
            "Treinando...\n",
            "  Batch    40  de    241.    Tempo: 0:00:09.\n",
            "  Batch    80  de    241.    Tempo: 0:00:17.\n",
            "  Batch   120  de    241.    Tempo: 0:00:26.\n",
            "  Batch   160  de    241.    Tempo: 0:00:35.\n",
            "  Batch   200  de    241.    Tempo: 0:00:43.\n",
            "  Batch   240  de    241.    Tempo: 0:00:52.\n",
            "\n",
            "  Perda m√©dia do treinamento: 0.08\n",
            "  √©poca de treinamento levou : 0:00:52\n",
            "\n",
            "Executando Valida√ß√£o...\n",
            "  Acur√°cia: 0.81\n",
            "  Valida√ß√£o perda (Loss): 0.63\n",
            "  Valida√ß√£o levou: 0:00:02\n",
            "\n",
            "======== √âpoca 4 / 4 ========\n",
            "Treinando...\n",
            "  Batch    40  de    241.    Tempo: 0:00:09.\n",
            "  Batch    80  de    241.    Tempo: 0:00:17.\n",
            "  Batch   120  de    241.    Tempo: 0:00:26.\n",
            "  Batch   160  de    241.    Tempo: 0:00:35.\n",
            "  Batch   200  de    241.    Tempo: 0:00:43.\n",
            "  Batch   240  de    241.    Tempo: 0:00:52.\n",
            "\n",
            "  Perda m√©dia do treinamento: 0.10\n",
            "  √©poca de treinamento levou : 0:00:52\n",
            "\n",
            "Executando Valida√ß√£o...\n",
            "  Acur√°cia: 0.81\n",
            "  Valida√ß√£o perda (Loss): 0.63\n",
            "  Valida√ß√£o levou: 0:00:02\n",
            "\n",
            "Treinamento completo!\n",
            "Tempo total de treinamento 0:03:35 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Esse c√≥digo √© baseado no `run_glue.py`\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Seta o valor 'seed' em todo lugar para tornar reproduz√≠vel\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# Vamos guardar os valores de perda do treinamento e valida√ß√£o, acur√°ria e tempos de execu√ß√£o.\n",
    "training_stats = []\n",
    "\n",
    "# Medir o total do tempo de treinamento para toda execu√ß√£o\n",
    "total_t0 = time.time()\n",
    "\n",
    "# para cada √©poca\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Treinamento\n",
    "    # ========================================\n",
    "    \n",
    "    # Executa um passo inteiro em todo conjunto de treinamento\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== √âpoca {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Treinando...')\n",
    "\n",
    "    # Mede quando tempo a √©poca de treinamento demora\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reseta a perda total para esta √©poca\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Coloca o modelo em modo de treinamento.\n",
    "    # Essa chamada para `train` apenas muda o modo, mas n√£o executa o treinamento.\n",
    "    # as camadas `dropout` e `batchnorm` tem comportamento diferente durante o treinamento\n",
    "    # (veja mais: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # Para cada batch dos nossos dados de treinamento\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Atualiza progresso a cada 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calcula o tempo em minutos.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Imprime o progresso.\n",
    "            print('  Batch {:>5,}  de  {:>5,}.    Tempo: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Retira esse batch de treinamento do nosso dataloader. \n",
    "        #\n",
    "        # Agora que retiramos esse batch, tamb√©m vamos copiar cada tensor para a GPU usando o m√©todo `to`, se necess√°rio.\n",
    "        #\n",
    "        # `batch` cont√©m tr√™s tensores pytorch:\n",
    "        #   [0]: ids de entrada \n",
    "        #   [1]: m√°scaras de aten√ß√£o\n",
    "        #   [2]: r√≥tulos\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Sempre limpe qualquer gradiente calculado anteriormente antes de executar o passo de \n",
    "        # backward, pois o PyTorch n√£o faz isso automaticamente, j√° que acumular os gradientes √©\n",
    "        # importante para o treinamento das RNNs. \n",
    "        # (https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Executa o passo forward (avalia o modelo no batch de treinamento).\n",
    "        # Documenta√ß√£o para essa fun√ß√£o: \n",
    "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "        # Retorna n√∫meros diferentes de par√¢metros, dependendo de qual argumento foi passado e quais flags foram setadas.\n",
    "        # Aqui, vai retornar a perda (loss) e os \"logits\", sa√≠das do modelo antes da ativa√ß√£o\n",
    "        loss, logits = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "\n",
    "        # Acumula a perda do treinamento de todos os batches ent√£o podemos calcular a m√©dia da perda no final. \n",
    "        # `loss` √© um Tensor contendo um valor √∫nico, a fun√ß√£o `.item()` apenas retorna o valor Python do tensor.\n",
    "        \n",
    "        # com a vers√£o nova do Transformers (4.x) aqui d√° erro\n",
    "        total_train_loss += loss.item()\n",
    "        \n",
    "        # Executa o passo backward para calcular os gradientes\n",
    "        loss.backward()\n",
    "\n",
    "        # Corte a norma dos gradientes para 1.0., para ajudar a prevenir o problema de \"exploding gradients\".\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Atualiza par√¢metros e passa uma etapa usando o gradiente calculado.\n",
    "        # O otimizador dita o \"update rule\", ou seja, como os par√¢metros s√£o modificados com base \n",
    "        # nos gradientes, taxa de aprendizagem, etc\n",
    "        optimizer.step()\n",
    "\n",
    "        # Atualiza taxa de aprendizagem\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calcula a perda m√©dia sobre todos os batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Mede quanto tempo levou essa √©poca\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Perda m√©dia do treinamento: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  √©poca de treinamento levou : {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Valida√ß√£o\n",
    "    # ========================================\n",
    "    # Ap√≥s a conclus√£o de cada √©poca de treinamento, vamos medir nosso desempenho em nosso conjunto de valida√ß√£o;\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Executando Valida√ß√£o...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Coloca o modelo no modo de avalia√ß√£o, ou seja, as camadas dropout ter√£o comportamento diferente\n",
    "    model.eval()\n",
    "\n",
    "    # Vari√°veis de rastreamento\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Avalia os dados para uma √©poca\n",
    "    for batch in validation_dataloader:\n",
    "        \n",
    "        # Retira esse batch de treinamento do nosso dataloader. \n",
    "        #\n",
    "        # Agora que retiramos o batch, vaos copiar cada tensor para nossa GPU com o m√©todo `to`, se estamos usando GPU\n",
    "        #\n",
    "        # `batch` cont√©m 3 tensores pytorch:\n",
    "        #   [0]: ids de entrada \n",
    "        #   [1]: m√°scaras de aten√ß√£o\n",
    "        #   [2]: r√≥tulos\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        \n",
    "        # Informa pytorch para n√£o n√£o se preocupar em construir o gr√°fico de computa√ß√£o durante o passo forward,\n",
    "        # j√° que precisa apenas no passo backprop (treinamento).\n",
    "        with torch.no_grad():        \n",
    "\n",
    "            # Passo Forward, calcula as perdi√ß√µes logit.\n",
    "            # token_type_ids √© o mesmo que os \"segment ids\", que diferencia as senten√ßas 1 e 2 em uma tarefa com 2 senten√ßas\n",
    "            # Documenta√ß√£o da fun√ß√£o `model`: \n",
    "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "            # Pega as sa√≠das \"logits\" do model, valores pr√©vios √† aplica√ß√£o da fun√ß√£o de ativa√ß√£o como a softmax.\n",
    "            (loss, logits) = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            \n",
    "        # Acumula a perda da valida√ß√£o\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move os logits e r√≥tulos para CPU, se necess√°rio\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Calcula a acur√°cia desse batch nas frases de teste, e acumula sobre todos os batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Imprime a acur√°cia final para a execu√ß√£o da valida√ß√£o.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Acur√°cia: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calcula a m√©dia da perda sobre todos os batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Mede quanto tempo levou a valida√ß√£o\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Valida√ß√£o perda (Loss): {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Valida√ß√£o levou: {:}\".format(validation_time))\n",
    "\n",
    "    # Grava as estat√≠sticas para esta √©poca.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Treinamento completo!\")\n",
    "\n",
    "print(\"Tempo total de treinamento {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos ver o resumo do processo de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Mostra n√∫meros com duas casas decimais\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Cria um DataFrame das nossas estat√≠sticas de treinamento\n",
    "df_stats = pd.DataFrame(data=training_stats)\n",
    "\n",
    "# Usa a √©poca como o √≠ndice da linha\n",
    "df_stats = df_stats.set_index('epoch')\n",
    "\n",
    "# For√ßar o agrupamento dos cabe√ßalho da coluna \n",
    "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
    "\n",
    "# Mostra a tabela\n",
    "df_stats"
   ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.51</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0:00:52</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.33</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0:00:52</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.22</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0:00:52</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.16</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0:00:52</td>\n",
              "      <td>0:00:02</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.51         0.45           0.79       0:00:52         0:00:02\n",
              "2               0.33         0.48           0.80       0:00:52         0:00:02\n",
              "3               0.22         0.57           0.80       0:00:52         0:00:02\n",
              "4               0.16         0.63           0.81       0:00:52         0:00:02"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que, enquanto a perda de treinamento est√° diminuindo a cada √©poca, a perda de valida√ß√£o est√° aumentando! Isso sugere que estamos treinando nosso modelo por muito tempo e que ele est√° se ajustando demais aos dados de treinamento.\n",
    "\n",
    "(Para refer√™ncia, estamos usando 7.695 amostras de treinamento e 856 amostras de valida√ß√£o).\n",
    "\n",
    "A perda de valida√ß√£o √© uma medida mais precisa do que a precis√£o, porque com a precis√£o n√£o nos importamos com o valor de sa√≠da exato, mas apenas em que lado de um limite ele cai.\n",
    "\n",
    "Se estivermos prevendo a resposta correta, mas com menos confian√ßa, a perda de valida√ß√£o pegar√° isso, mas a precis√£o n√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Usando estilo\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Aumentando o tamanho e fonte \n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plotando a curva de aprendizagem\n",
    "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Treinamento\")\n",
    "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Valida√ß√£o\")\n",
    "\n",
    "\n",
    "# Adicionando t√≠tulos\n",
    "plt.title(\"Perda de treinamento e valida√ß√£o\")\n",
    "plt.xlabel(\"√âpoca\")\n",
    "plt.ylabel(\"Perda\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "\n",
    "plt.show()"
   ],
   "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desempenho no conjunto de teste ##\n",
    "\n",
    "Agora, carregaremos o conjunto de dados *holdout* e preparar as entradas, como fizemos com o conjunto de treinamento. \n",
    "\n",
    "Em seguida, avaliaremos as previs√µes usando o [coeficiente de correla√ß√£o de Matthew](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html), m√©trica usada para avaliar o desempenho no CoLA. Com essa m√©trica, +1 √© a melhor pontua√ß√£o e -1 √© a pior pontua√ß√£o. Dessa forma, podemos ver nosso desempenho em rela√ß√£o aos modelos de √∫ltima gera√ß√£o para essa tarefa espec√≠fica.\n",
    "\n",
    "### Prepara√ß√£o de dados ###\n",
    "\n",
    "Precisaremos aplicar todas as mesmas etapas que fizemos para os dados de treinamento para preparar nosso conjunto de dados de teste.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carrega o dataset em um dataframe pandas\n",
    "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "\n",
    "# Imprime o n√∫mero de frases\n",
    "print('N√∫mero de frases de teste: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "# Cria as listas de frases e r√≥tulos\n",
    "sentences = df.sentence.values\n",
    "labels = df.label.values\n",
    "\n",
    "# Tokeniza todas as senten√ßas e mapeia os tokens em seus IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# Para cada frase\n",
    "for sent in sentences:\n",
    "    # `encode_plus` vai:\n",
    "    #   (1) Tokenizar a frase\n",
    "    #   (2) Adicionar o token `[CLS]` no in√≠cio\n",
    "    #   (3) Adicionar o token `[SEP]` no final.\n",
    "    #   (4) Mapear tokens aos seus IDs.\n",
    "    #   (5) Preencher ou truncar a frase at√© `max_length`\n",
    "    #   (6) Criar m√°scara de aten√ß√£o para os tokens [PAD].\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Senten√ßa a ser codificada\n",
    "                        add_special_tokens = True, # Adiciona '[CLS]' e '[SEP]'\n",
    "                        max_length = 64,           # Preenche & trunca todas as senten√ßas\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Constr√≥i m√°scara de aten√ß√£o\n",
    "                        return_tensors = 'pt',     # Retorna tensores pytorch.\n",
    "                   )\n",
    "    \n",
    "    # Adiciona a senten√ßa codificada na lista\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # E sua m√°scara de aten√ß√£o (simplesmente diferencia preenchimento (PAD) de n√£o-pad).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Converte as listas em tensores.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Seta o batch size.  \n",
    "batch_size = 32  \n",
    "\n",
    "# Cria o DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ],
   "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N√∫mero de frases de teste: 516\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avalia√ß√£o no conjunto de teste ###\n",
    "\n",
    "Com o conjunto de teste preparado, podemos aplicar nosso modelo ajustado para gerar previs√µes no conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predi√ß√£o no conjunto de teste\n",
    "\n",
    "print('Predi√ß√£o de r√≥tulos para {:,} frases de teste...'.format(len(input_ids)))\n",
    "\n",
    "# coloca o modele em modo de avalia√ß√£o\n",
    "model.eval()\n",
    "\n",
    "# Vari√°veis de rastreamento\n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predi√ß√£o \n",
    "for batch in prediction_dataloader:\n",
    "  # Adiciona o batch na GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Retira as entradas do dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Informa o modelo para n√£o computar gradientes, salvando mem√≥ria e acelerando a predi√ß√£o \n",
    "  with torch.no_grad():\n",
    "      # Passo Forward, calcula as predi√ß√µes logit\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move as logits e r√≥tulos para CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Armazen predi√ß√µes e r√≥tulos verdadeiros\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    FIM.')"
   ],
   "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predi√ß√£o de r√≥tulos para 516 frases de teste...\n",
            "    FIM.\n"
          ],
          "name": "stdout"
        }
      ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A precis√£o no *benchmark* CoLA √© medida usando o ‚Äúcoeficiente de correla√ß√£o de Matthews‚Äù (MCC).\n",
    "\n",
    "Usamos MCC aqui porque as classes s√£o desequilibradas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Inst√¢ncias positivas: %d de %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))\n"
   ],
   "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inst√¢ncias positivas: 354 de 516 (68.60%)\n"
          ],
          "name": "stdout"
        }
      ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "matthews_set = []\n",
    "\n",
    "# Avaliando cada batch de teste usando MCC\n",
    "print('Calculando MCC para cada batch...')\n",
    "\n",
    "# Para cada batch\n",
    "for i in range(len(true_labels)):\n",
    "  \n",
    "  # As predi√ß√µes para este batch s√£o a 2a. coluna do ndarray (uma coluna para \"0\" e outra para \"1\"  \n",
    "  # Pega o r√≥tulo com o maior valor e transforma para uma lista de 0s e 1s.\n",
    "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "  \n",
    "  # Calcula e armazena o coef para este batch.  \n",
    "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "  matthews_set.append(matthews)"
   ],
   "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculando MCC para cada batch...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        }
      ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pontua√ß√£o final ser√° baseada em todo o conjunto de teste, mas vamos dar uma olhada nas pontua√ß√µes dos lotes individuais para ter uma no√ß√£o da variabilidade da m√©trica entre os lotes.\n",
    "\n",
    "Cada lote cont√©m 32 senten√ßas, exceto o √∫ltimo lote que cont√©m apenas (516% 32) = 4 senten√ßas de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria um barplot mostrando o MCC para cada batch dos nossos exemplos de teste.\n",
    "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
    "\n",
    "plt.title('MCC por Batch')\n",
    "plt.ylabel('MCC Score (-1 a +1)')\n",
    "plt.xlabel('Batch #')\n",
    "\n",
    "plt.show()"
   ],
   "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora combinaremos os resultados de todos os lotes e calcularemos nossa pontua√ß√£o final no MCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combina os resultados para todos os batches. \n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Para cada exemplo, pega o r√≥tulo (0 or 1) com maior score\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combina os r√≥tulos corretor para cada batch em uma √∫nica lista.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Calcula o MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('Total MCC: %.3f' % mcc)"
   ],
         "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: 0.550\n"
          ],
          "name": "stdout"
        }
      ]

  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legal! Em cerca de meia hora e sem fazer nenhum ajuste de hiperpar√¢metro (ajustando a taxa de aprendizagem, √©pocas, tamanho do lote, propriedades ADAM, etc.), obtivemos uma boa pontua√ß√£o."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: Para maximizar a pontua√ß√£o, devemos remover o ‚Äúconjunto de valida√ß√£o‚Äù (que usamos para ajudar a determinar em quantas √©pocas treinar) e treinar em todo o conjunto de treinamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A biblioteca documenta a precis√£o esperada para este benchmark aqui como **49.23** ([ver tabela de classifica√ß√£o oficial](https://gluebenchmark.com/leaderboard/submission/zlssuBTm5XRs0aSKbFYGVIVdvbj1/-LhijX9VVmvJcvzKymxy)).\n",
    "\n",
    "## Conclus√£o ##\n",
    "\n",
    "Com um modelo BERT pr√©-treinado, podemos criar de forma r√°pida e eficaz um modelo de alta qualidade com o m√≠nimo de esfor√ßo e tempo de treinamento usando a interface *pytorch*, independentemente da tarefa PLN espec√≠fica em que estamos interessados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvar e carregar modelo ajustado ###\n",
    "\n",
    "A pr√≥xima c√©lula grava o modelo e o tokenizer no disco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Boa-pr√°tica: usar os nomes padr√£o dos modlos, para fazer load usando from_pretrained()\n",
    "\n",
    "output_dir = './model_save/'\n",
    "\n",
    "# Criar diret√≥rio de sa√≠da se necess√°rio\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Savando modelo em %s\" % output_dir)\n",
    "\n",
    "# Salva um modelo treinado, sua configura√ß√£o e tokenizador com `save_pretrained()`.\n",
    "# Eles podem ser carregados com `from_pretrained()`\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Cuida do treinamento paralelo/distribu√≠do\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "# Boa-pr√°tica: salve os argumentos de treinamento junto com o modelo\n",
    "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
   ],
         "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Savando modelo em ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/vocab.txt',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]

  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos verificar os tamanhos dos arquivos, por curiosidade. (no Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l --block-size=K ./model_save/\n"
   ],
         "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 427996K\n",
            "-rw-r--r-- 1 root root      1K Dec 10 19:33 config.json\n",
            "-rw-r--r-- 1 root root 427752K Dec 10 19:33 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root      1K Dec 10 19:33 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root      1K Dec 10 19:33 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root    227K Dec 10 19:33 vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]

  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O maior arquivo √© o peso do modelo, em torno de 418 megabytes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l --block-size=M ./model_save/pytorch_model.bin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para salvar seu modelo nas sess√µes do **Colab Notebook**, baixe-o em sua m√°quina local ou, de prefer√™ncia, copie-o para o Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montando Google Drive nesta inst√¢ncia \n",
    "from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "# Copia os arquivos do modelo num diret√≥rio do Google Drive.\n",
    "!cp -r ./model_save/ \"./drive/Shared drives/PLN/BERT Fine-Tuning/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As fun√ß√µes a seguir carregar√£o o modelo de volta do disco.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega um modelo treinado e seu vocabul√°rio\n",
    "model = model_class.from_pretrained(output_dir)\n",
    "tokenizer = tokenizer_class.from_pretrained(output_dir)\n",
    "\n",
    "# Copia o modelo na GPU\n",
    "model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
