{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "colab": {
      "name": "jupyter-bert-classificacao.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0cb9049145974d55b3e8c9b075c16185": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e6bc4fa3801b45e189c6e7f3de641c06",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4f3b06cac2094a61b00f9a13b55bfc1c",
              "IPY_MODEL_d00d3f968679442d9f69ba775ae843d1"
            ]
          }
        },
        "e6bc4fa3801b45e189c6e7f3de641c06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4f3b06cac2094a61b00f9a13b55bfc1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_38e4081b0ee2413a9b525a0fef919d89",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6787ebe6ab364f83b72b90406adc6589"
          }
        },
        "d00d3f968679442d9f69ba775ae843d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7a6bcf541fe14666ae9996eee77f5205",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "‚Äã",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 939kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c2c278cfcaca4e718bcbd866769e1842"
          }
        },
        "38e4081b0ee2413a9b525a0fef919d89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6787ebe6ab364f83b72b90406adc6589": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a6bcf541fe14666ae9996eee77f5205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c2c278cfcaca4e718bcbd866769e1842": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pieQOy1UThI"
      },
      "source": [
        "# Classifica√ß√£o com BERT\n",
        "\n",
        "Neste *notebook* voc√™ ver√° um exemplo de como usar o [BERT](https://arxiv.org/abs/1810.04805) para tarefa de classifica√ß√£o, usando a bilbioteca **Transformers** do **Hugging Faces**. \n",
        "\n",
        "Fontes:  \n",
        "\n",
        "- [BERT Fine-Tuning Tutorial with PyTorch](https://mccormickml.com/2019/07/22/BERT-fine-tuning/).\n",
        "- [Hugging Faces - Github](https://github.com/huggingface/transformers) e [Hugging Faces - site](https://huggingface.co/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bq0Z5iWeUThO"
      },
      "source": [
        "Primeiro, vamos verificar se temos GPU dispon√≠vel para nossa execu√ß√£o. N√£o se preocupe caso n√£o possua GPU, apenas o treinamento ser√° mais demorado.\n",
        "\n",
        "Caso voc√™ esteja executando no Colab, acesse: Edit ü°í Notebook Settings ü°í Hardware accelerator ü°í (GPU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iH3iyyMUThO",
        "outputId": "86b2e17d-168a-4d63-c5c9-bd37b306740a"
      },
      "source": [
        "import torch\n",
        "\n",
        "# Verificar se tem GPU dispon√≠vel\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Informa PyTorch para usar GPU\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('Existe(m)  %d GPU(s) dispon√≠vel(eis).' % torch.cuda.device_count())\n",
        "\n",
        "    print('Vamos usar a GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# Se n√£o tem...\n",
        "else:\n",
        "    print('Sem GPU dispon√≠vel, usando CPU.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Existe(m)  1 GPU(s) dispon√≠vel(eis).\n",
            "Vamos usar a GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6riA3KZUThQ"
      },
      "source": [
        "### Biblioteca Transformers com *Pytorch*\n",
        "\n",
        "Aqui vamos usar a interface *Pytorch* porque possui um bom equil√≠brio entre as APIs de alto n√≠vel (f√°ceis de usar, mas sem fornecer informa√ß√µes sobre como as coisas funcionam) e c√≥digo de tensorflow (que cont√©m muitos detalhes, mas n√£o t√£o f√°ceis de usar).\n",
        "\n",
        "No momento, a biblioteca **Hugging Face** √© a interface *Pytorch* mais utilizada para trabalhar com BERT. Al√©m de oferecer suporte a uma variedade de modelos pr√©-treinados, tamb√©m inclui modelos especializados para tarefas espec√≠ficas. Neste tutorial vamos usar *BertForSequenceClassification*.\n",
        "\n",
        "A biblioteca tamb√©m inclui classes espec√≠ficas de tarefas para classifica√ß√£o de *tokens*, resposta a perguntas (Q&A), previs√£o da pr√≥xima frase, etc. O uso dessas classes pr√©-constru√≠das simplifica o processo de modifica√ß√£o de BERT para nossos prop√≥sitos."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrbPDnszUThQ",
        "outputId": "c6392f9b-06d9-4e2d-a7d4-e753529d8682"
      },
      "source": [
        "# execute essa linha se estiver usando Colab\n",
        "#!pip install transformers\n",
        "!pip install transformers~=2.11.0\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers~=2.11.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 675kB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers~=2.11.0) (1.18.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 890kB 18.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers~=2.11.0) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers~=2.11.0) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers~=2.11.0) (20.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers~=2.11.0) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.1MB 41.7MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.8MB 44.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers~=2.11.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers~=2.11.0) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers~=2.11.0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers~=2.11.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers~=2.11.0) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers~=2.11.0) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers~=2.11.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers~=2.11.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers~=2.11.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers~=2.11.0) (2.10)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=12193703474a96ecbb9d9aad6b47fc3075c95ff466ca9352a6d3f2fa7c9950a1\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "_pii6c_iUThQ"
      },
      "source": [
        "### Carregando o conjunto de dados (CoLA)\n",
        "\n",
        "Usaremos o conjunto de dados do *Corpus of Linguistic Acceptability (CoLA)* para a classifica√ß√£o de uma √∫nica frase. √â um conjunto de frases rotuladas como gramaticalmente corretas ou incorretas. Foi publicado pela primeira vez em maio de 2018, e √© um dos testes inclu√≠dos no ‚ÄúBenchmark GLUE‚Äù em que competem modelos como o BERT.\n",
        "\n",
        "Fa√ßa *download* do dataset neste link: https://nyu-mll.github.io/CoLA/ e descompacte o conjunto de dados na mesma pasta em que est√° trabalhando.\n",
        "\n",
        "Ou, se estiver no Colab, use o comando abaixo:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgM7p28fUThR",
        "outputId": "604f5193-edff-49f6-ac86-6365e44075c2"
      },
      "source": [
        "# Usaremos o wget para baixar o conjunto de dados para o sistema de arquivos da inst√¢ncia Colab.\n",
        "!pip install wget\n",
        "\n",
        "import wget\n",
        "import os\n",
        "\n",
        "print('Baixando dataset...')\n",
        "\n",
        "# URL para baixar o dataset em formato zip.\n",
        "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
        "\n",
        "# Baixar arquivo (se n√£o temos ainda)\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')\n",
        "    \n",
        "# Dezipar o dataset (se ainda n√£o temos)\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9681 sha256=35059a9ac2524714809ee10c400fbfd11a49e6ec1c351e78af2f174b204d2546\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Baixando dataset...\n",
            "Archive:  cola_public_1.1.zip\n",
            "   creating: cola_public/\n",
            "  inflating: cola_public/README      \n",
            "   creating: cola_public/tokenized/\n",
            "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
            "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
            "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
            "   creating: cola_public/raw/\n",
            "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
            "  inflating: cola_public/raw/in_domain_train.tsv  \n",
            "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%% md\n"
        },
        "id": "U6KkxO5mUThR"
      },
      "source": [
        "### An√°lise\n",
        "\n",
        "Podemos ver pelos nomes dos arquivos que temos as vers√µes originais e as tokenizadas dos dados.\n",
        "\n",
        "N√£o vamos usar a vers√£o pr√©-tokenizada porque, para aplicar o nosso modelo BERT pr√©-treinado, devemos usar o tokenizador fornecido pelo modelo. Isso porque: (1) o modelo tem um vocabul√°rio espec√≠fico e fixo e (2) o tokenizador BERT tem uma maneira particular de lidar com palavras fora do vocabul√°rio.\n",
        "\n",
        "Usaremos a biblioteca *pandas* para analisar o conjunto de treinamento e examinar algumas de suas propriedades."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "BrpMue0gUThR",
        "outputId": "7f62ff4b-9e81-4f2a-b627-34b9e2168999"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carrega o dataset em um dataframe pandas\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Imprime o n√∫mero de frases.\n",
        "print('N√∫mero de senten√ßas de treinamento: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Exibe 10 frases rand√¥micas do dataset\n",
        "df.sample(10)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N√∫mero de senten√ßas de treinamento: 8,551\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3335</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>There ran through the valley a rushing stream.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2853</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Carol cut her thumb.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5992</th>\n",
              "      <td>c_13</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Ate Bill his dinner?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2411</th>\n",
              "      <td>l-93</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>$5 will buy you a ticket.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8456</th>\n",
              "      <td>ad03</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Peter is the old pigs.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6383</th>\n",
              "      <td>d_98</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>You may pick any flower except the rose.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>906</th>\n",
              "      <td>bc01</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Joe likes his bar, and Sally's patrons do too.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3417</th>\n",
              "      <td>l-93</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>The phone company billed $10 to me.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3977</th>\n",
              "      <td>ks08</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>Oliver addressed the king the letter.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4189</th>\n",
              "      <td>ks08</td>\n",
              "      <td>0</td>\n",
              "      <td>*</td>\n",
              "      <td>One of the story has appeared in your newspaper.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     sentence_source  ...                                          sentence\n",
              "3335            l-93  ...    There ran through the valley a rushing stream.\n",
              "2853            l-93  ...                              Carol cut her thumb.\n",
              "5992            c_13  ...                              Ate Bill his dinner?\n",
              "2411            l-93  ...                         $5 will buy you a ticket.\n",
              "8456            ad03  ...                            Peter is the old pigs.\n",
              "6383            d_98  ...          You may pick any flower except the rose.\n",
              "906             bc01  ...    Joe likes his bar, and Sally's patrons do too.\n",
              "3417            l-93  ...               The phone company billed $10 to me.\n",
              "3977            ks08  ...             Oliver addressed the king the letter.\n",
              "4189            ks08  ...  One of the story has appeared in your newspaper.\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "oPl1u-8BUThS"
      },
      "source": [
        "As duas propriedades importantes s√£o as frases (*sentence*) e seus r√≥tulos (*label*), que podem ser 0 = incorreta e 1 = correta.\n",
        "\n",
        "Aqui est√£o cinco frases que s√£o rotuladas como incorretas gramaticalmente (em ingl√™s). Observe como essa tarefa √© muito mais dif√≠cil do que algo como an√°lise de sentimento!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "J4rp0KUmUThS",
        "outputId": "d2fc88ce-5eed-4663-e831-65083fbabbee"
      },
      "source": [
        "df.loc[df.label == 0].sample(5)[['sentence', 'label']]\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1387</th>\n",
              "      <td>The place which I live at is the place where R...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3498</th>\n",
              "      <td>A pastor was executed, notwithstanding on many...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8194</th>\n",
              "      <td>I sent she away.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2674</th>\n",
              "      <td>Books send easily to children.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1365</th>\n",
              "      <td>The boy's guardian's we elected employer presi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  label\n",
              "1387  The place which I live at is the place where R...      0\n",
              "3498  A pastor was executed, notwithstanding on many...      0\n",
              "8194                                   I sent she away.      0\n",
              "2674                     Books send easily to children.      0\n",
              "1365  The boy's guardian's we elected employer presi...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPOPhM5uUThT"
      },
      "source": [
        "Vamos extrair as frases e seus r√≥tulos do nosso corpus de treinamento como *numpy ndarrays*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "id": "Ozgqh2jUUThT"
      },
      "source": [
        "# Lista de senten√ßas e seus r√≥tulos\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "eZrtVcKtUThT"
      },
      "source": [
        "### Tokeniza√ß√£o\n",
        "\n",
        "Agora vamos transformar nosso conjunto de dados no formato em que o BERT pode ser treinado.\n",
        "\n",
        "Para alimentar o BERT com nosso texto, ele deve ser dividido em *tokens* e, em seguida, esses *tokens* devem ser mapeados para seu √≠ndice no vocabul√°rio do tokenizador.\n",
        "\n",
        "A tokeniza√ß√£o deve ser realizada pelo tokenizador inclu√≠do no modelo BERT que estamos trabalhando, que vamos baixar no c√≥digo abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "0cb9049145974d55b3e8c9b075c16185",
            "e6bc4fa3801b45e189c6e7f3de641c06",
            "4f3b06cac2094a61b00f9a13b55bfc1c",
            "d00d3f968679442d9f69ba775ae843d1",
            "38e4081b0ee2413a9b525a0fef919d89",
            "6787ebe6ab364f83b72b90406adc6589",
            "7a6bcf541fe14666ae9996eee77f5205",
            "c2c278cfcaca4e718bcbd866769e1842"
          ]
        },
        "id": "N7x158YBUThT",
        "outputId": "7313952b-f603-4e0a-9a70-3fd3adf86b32"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Carregar o tokenizador BERT.\n",
        "print('Carregando tokenizador BERT...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Carregando tokenizador BERT...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0cb9049145974d55b3e8c9b075c16185",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti‚Ä¶"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%% md\n"
        },
        "id": "vH1IYgJnUThU"
      },
      "source": [
        "Vamos aplicar o tokenizador a uma frase para ver a sa√≠da."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%% \n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF-KTEmyUThU",
        "outputId": "16b0c4c3-721b-471b-e3b6-3d3a43805b3d"
      },
      "source": [
        "# Frase original\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Frase dividida em tokens\n",
        "print('Tokenizada: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Senten√ßa mapeada em token ids\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Tokenizada:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
            "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "NIaObrfhUThU"
      },
      "source": [
        "Quando realmente convertermos todas as nossas senten√ßas, usaremos a fun√ß√£o ```tokenize.encode``` para lidar com ambas as etapas, em vez de chamar as fun√ß√µes que usamos acima separadamente.\n",
        "\n",
        "Antes de fazermos isso, precisamos falar sobre alguns dos requisitos de formata√ß√£o do BERT.\n",
        "\n",
        "### Formata√ß√£o\n",
        "\n",
        "O c√≥digo acima omitiu algumas etapas de formata√ß√£o necess√°rias que veremos aqui.\n",
        "\n",
        "Precisamos:\n",
        "1. Adicionar *tokens* especiais no in√≠cio e fim de cada frase.\n",
        "2. Prencher e truncar todas as frases para terem o mesmo comprimento.\n",
        "3. Diferenciar explicitamente *tokens* reais de *tokens* de preenchimento (PAD) com a ‚Äúm√°scara de aten√ß√£o‚Äù.\n",
        "\n",
        "**Tokens especiais**\n",
        "[SEP] - No final de cada frase, precisamos acrescentar o token especial [SEP], que √© usado em tarefas de duas senten√ßas, onde BERT recebe duas senten√ßas separadas e √© solicitado a determinar algo (por exemplo, a resposta √† pergunta na senten√ßa A pode ser encontrada na senten√ßa B).\n",
        "\n",
        "[CLS] - Para tarefas de classifica√ß√£o, devemos acrescentar o [CLS] ao in√≠cio de cada frase. Como o BERT consiste em 12 camadas de Tranformer, cada uma recebe uma lista de *embeddings* e produz o mesmo n√∫mero de *embeddings* na sa√≠da (com outros valores), na sa√≠da do transformador final (12¬∫), apenas o primeiro *embedding* (correspondente ao *token* [CLS]) √© usado pelo classificador .\n",
        "\n",
        "‚ÄúO primeiro *token* de cada sequ√™ncia √© sempre um *token* de classifica√ß√£o especial ([CLS]), onde o estado oculto final deste *token* √© usado como a representa√ß√£o da sequ√™ncia agregada para tarefas de classifica√ß√£o.‚Äù (do artigo BERT)\n",
        "\n",
        "N√£o precisamos pensar em estrat√©gias de *pool* sobre os *embeddings* finais, pois nesse token [CLS] de classifica√ß√£o, o modelo codificou tudo o que precisamos para a classifica√ß√£o naquele √∫nico vetor de incorpora√ß√£o de 768 valores. J√° est√° feito o *pool* para n√≥s!\n",
        "\n",
        "*Comprimento da frase e m√°scara de aten√ß√£o*\n",
        "\n",
        "As senten√ßas em nosso conjunto de dados obviamente t√™m comprimentos variados, ent√£o como o BERT lida com isso?\n",
        "\n",
        "BERT tem duas restri√ß√µes:\n",
        "\n",
        "- Todas as frases devem ser preenchidas ou truncadas em um √∫nico comprimento fixo.\n",
        "- O comprimento m√°ximo da frase √© 512 *tokens*.\n",
        "\n",
        "O preenchimento √© feito com um *token* especial [PAD], que est√° no √≠ndice 0 no vocabul√°rio BERT.\n",
        "\n",
        "A ‚ÄúM√°scara de Aten√ß√£o‚Äù √© simplesmente uma matriz de 1s e 0s indicando quais *tokens* s√£o de preenchimento e quais n√£o s√£o (parece meio redundante, n√£o √© ?). Essa m√°scara diz ao mecanismo de ‚ÄúAutoaten√ß√£o‚Äù do BERT para n√£o incorporar esses *tokens* (PAD) em sua interpreta√ß√£o da frase.\n",
        "\n",
        "O comprimento m√°ximo afeta a velocidade de treinamento e avalia√ß√£o. Por exemplo, com um Tesla K80:\n",
        "\n",
        "MAX_LEN = 128 --> Cada √©poca leva ~5:28 para treinar\n",
        "\n",
        "MAX_LEN = 64 --> Cada √©poca leva ~2:57 para treinar\n",
        "\n",
        "**Tokenizar o conjunto de dados**\n",
        "\n",
        "A biblioteca Transformers fornece uma fun√ß√£o ```encode``` que tratar√° da maioria das etapas de an√°lise e prepara√ß√£o de dados para n√≥s.\n",
        "\n",
        "Antes de estarmos prontos para codificar nosso texto, precisamos decidir sobre o comprimento m√°ximo de frase para preenchimento ou truncamento.\n",
        "\n",
        "A c√©lula abaixo realizar√° uma passagem de tokeniza√ß√£o em nosso conjunto de dados para medir o comprimento m√°ximo da frase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-bVl31sUThV",
        "outputId": "e1cc7fe2-8452-41b9-d5b2-142f20fae0d6"
      },
      "source": [
        "max_len = 0\n",
        "\n",
        "# Para cada frase\n",
        "for sent in sentences:\n",
        "\n",
        "    # Tokeniza o texto e adiciona os tokens `[CLS]` e `[SEP]`\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Atualiza o comprimento m√°ximo da frase\n",
        "    max_len = max(max_len, len(input_ids))\n",
        "\n",
        "print('Frase com tamanho m√°ximo no nosso dataset: ', max_len)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Frase com tamanho m√°ximo no nosso dataset:  47\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "4Ph70NljUThW"
      },
      "source": [
        "Para o caso de haver algumas senten√ßas mais longas no conjunto de teste, vams setar nosso comprimento m√°ximo em 64.\n",
        "\n",
        "Agora estamos prontos para realizar a tokeniza√ß√£o.\n",
        "\n",
        "A fun√ß√£o ```tokenizer.encode_plus``` realiza v√°rias etapas para n√≥s:\n",
        "\n",
        "1. Divide a frase em *tokens*.\n",
        "2. Adiciona os *tokens* especiais [CLS] e [SEP].\n",
        "3. Mapeia os *tokens* para seus IDs.\n",
        "4. Preenche ou trunca todas as frases com o mesmo comprimento.\n",
        "5. Cria as m√°scaras de aten√ß√£o que diferenciam explicitamente *tokens* reais de *tokens* [PAD].\n",
        "\n",
        "As primeiras quatro etapas s√£o realizadas pela fun√ß√£o ```tokenizer.encode```, mas vamos usar a ```tokenizer.encode_plus``` para a quinta etapa (m√°scaras de aten√ß√£o). [Documenta√ß√£o aqui](https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-99KsnSRUThW",
        "outputId": "3a90651d-b8ef-4d6d-e79c-b05723da4f23"
      },
      "source": [
        "# Tokeniza todas as frases e mapeia os tokens em seus IDs\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# Para cada frase\n",
        "for sent in sentences:\n",
        "    # `encode_plus` far√° o seguinte:\n",
        "    #   (1) Tokeniza a frase\n",
        "    #   (2) Adiciona o token `[CLS]` no inicio\n",
        "    #   (3) Adiciona o token `[SEP]` no final\n",
        "    #   (4) Mapeia os tokens em seus IDs.\n",
        "    #   (5) Adiciona preenchimento (pad) ou trunca a frase at√° o comprimento m√°ximo (`max_length`)\n",
        "    #   (6) Cria m√°scara de aten√ß√£o para os tokens [PAD].\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Frase a ser codificada\n",
        "                        add_special_tokens = True, # Adiciona '[CLS]' e '[SEP]'\n",
        "                        max_length = 64,           # Preenche & trunca todas as frases\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Constr√≥i m√°scaras de aten√ß√£o\n",
        "                        return_tensors = 'pt',     # Returna tensores pytorch.\n",
        "                   )\n",
        "    \n",
        "    # Adiciona a frase codificada na lista\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # E sua m√°scara de aten√ß√£o (simplesmente diferencia tokens reais de tokens de preenchimento - PAD).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Converte a lista em tensores\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Imprime frase 0, agora como uma lista de IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
            "Token IDs: tensor([  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n",
            "         2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "LpEzUITwUThX"
      },
      "source": [
        "### Divis√£o dos dados - treinamento e valida√ß√£o\n",
        "\n",
        "Precisamos agora dividir nosso conjunto de treinamento, em 90% para treinamento e 10% para valida√ß√£o.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbziTD_xUThX",
        "outputId": "368c2ae2-bb8d-473b-dcde-26c42d5c9a22"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combina as entradas de treinamento em um TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Criar uma divis√£o 90-10 para treinamento-valida√ß√£o.\n",
        "\n",
        "# Calcula o n√∫mero de inst√¢ncias para incluir em cada divis√£o\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide o dataset pegando randomicamente as inst√¢ncia \n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} inst√¢ncias de treinamento'.format(train_size))\n",
        "print('{:>5,} inst√¢ncias de valida√ß√£o'.format(val_size))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7,695 inst√¢ncias de treinamento\n",
            "  856 inst√¢ncias de valida√ß√£o\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11MFCzUbUThY"
      },
      "source": [
        "Vamos criar um iterador para nosso conjunto de dados usando a classe *DataLoader*, para economizar mem√≥ria durante o treinamento, visto que, ao contr√°rio de um *loop* com *for*, com o iterador o conjunto de dados inteiro n√£o precisa ser carregado na mem√≥ria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFdSvaIyUThY"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# O DataLoader precisa saber no tamanho do batch size para treinamento, ent√£o vamos espeficiar\n",
        "# Para o fine-tuning em uma tarefa, os autores recomendam um batch size de 16 ou 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Criar os DataLoaders para nossos conjuntos de treinamento e teste\n",
        "# Vamos pegar inst√¢ncias de treinamento em ordem aleat√≥ria\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # Exemplos de treinamento\n",
        "            sampler = RandomSampler(train_dataset), # Seleciona batches aleatoriamente\n",
        "            batch_size = batch_size # Treina com este batch size.\n",
        "        )\n",
        "\n",
        "# Para valida√ß√£o, a ordem n√£o importa, ent√£o vamos mant√™-la sequencial\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # Exemplos de valida√ß√£o.\n",
        "            sampler = SequentialSampler(val_dataset), # Executa os batches sequencialmente.\n",
        "            batch_size = batch_size # Avalia com este batch size.\n",
        "        )"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fF0XtfxIUThY"
      },
      "source": [
        "## Modelo de classifica√ß√£o\n",
        "\n",
        "Agora que nossos dados de entrada est√£o formatados corretamente, √© hora de especializar o modelo BERT.\n",
        "\n",
        "### BertForSequenceClassification\n",
        "\n",
        "Para a tarefa de classifica√ß√£o, vamos modificar o modelo BERT pr√©-treinado para fornecer sa√≠das para classifica√ß√£o e, em seguida, treinar todo modelo em nosso conjunto de dados at√© que esteja especializado para nossa tarefa.\n",
        "\n",
        "Felizmente, a implementa√ß√£o *Pytorch* do Hugging Face inclui um conjunto de interfaces projetadas para uma variedade de tarefas de PLN. Embora essas interfaces sejam todas constru√≠das em cima de um modelo BERT treinado, cada uma tem diferentes camadas superiores e tipos de sa√≠da projetados para nossa tarefa PLN espec√≠fica.\n",
        "\n",
        "Aqui est√° a lista atual de classes fornecidas para a especializa√ß√£o da tarefa (ajuste fino ou *fine tuning*):\n",
        "\n",
        "1. BertModel\n",
        "1. BertForPreTraining\n",
        "1. BertForMaskedLM\n",
        "1. BertForNextSentencePrediction\n",
        "1. BertForSequenceClassification (**usaremos aqui**)\n",
        "1. BertForTokenClassification\n",
        "1. BertForQuestionAnswering\n",
        "\n",
        "A documenta√ß√£o para eles pode ser encontrada [aqui](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html).\n",
        "\n",
        "Estaremos usando *BertForSequenceClassification*, modelo BERT com uma camada linear √∫nica adicionada no topo para classifica√ß√£o, que ser√° usado como um classificador de frases. A medida que alimentamos os dados de entrada, todo o modelo BERT pr√©-treinado e a camada adicional de classifica√ß√£o n√£o treinada ser√£o treinados em nossa tarefa espec√≠fica.\n",
        "\n",
        "OK, vamos carregar o BERT! Existem alguns modelos diferentes de BERT pr√©-treinados dispon√≠veis. ‚Äúbert-base-uncased‚Äù, modell em ingl√™s, significa a vers√£o que tem apenas letras min√∫sculas (‚Äúsem caixa‚Äù) e √© a vers√£o menor das duas (‚Äúbase‚Äù vs ‚Äúlarge‚Äù).\n",
        "\n",
        "A documenta√ß√£o do m√©todo ```from_pretrained``` pode ser encontrada [aqui](https://huggingface.co/transformers/v2.2.0/main_classes/model.html#transformers.PreTrainedModel.from_pretrained), com os par√¢metros adicionais definidos [aqui](https://huggingface.co/transformers/v2.2.0/main_classes/configuration.html#transformers.PretrainedConfig)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ1XxRwlUThY",
        "outputId": "9534de38-4405-4b4e-da69-012c118a33ee"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Carrega a classe BertForSequenceClassification, o modelo pre-treinado com uma camada linear simples no topo\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Usa o BERT com 12 camadas, com vocabulario com caixa baixa\n",
        "    num_labels = 2, # O n√∫mero de sa√≠das, ou r√≥tulos, do nosso modelo (classifica√ß√£o bin√°ria em nosso caso)\n",
        "                    # Para tarefas com mais classes (multi-classe), podemos aumentar esse n√∫mero\n",
        "    output_attentions = False, # Se o modelo deve retornar os pesos de aten√ß√£o\n",
        "    output_hidden_states = False, # Se o modelo deve retornar todos estados escondidos\n",
        ")\n",
        "\n",
        "# Se voc√™ tem GPU, configura o pytorch para executar o modelo na GPU\n",
        "model.cuda()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGO0u1gjUThZ"
      },
      "source": [
        "Apenas por curiosidade, podemos navegar por todos os par√¢metros do modelo.\n",
        "\n",
        "Na c√©lula abaixo, imprimimos os nomes e dimens√µes dos pesos para:\n",
        "\n",
        "1. A camada de incorpora√ß√£o.\n",
        "1. O primeiro dos doze transformadores.\n",
        "1. A camada de sa√≠da."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xnrLqqkUThZ",
        "outputId": "9aafea18-6c67-42d6-9856-2f07f903e84f"
      },
      "source": [
        "# Lista todos os paremtros do modelo como uma lista de tuplas\n",
        "params = list(model.named_parameters())\n",
        "\n",
        "print('O modelo BERT tem {:} par√¢metros diferentes.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Camada de incorpora√ß√£o (Embedding) ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Primeiro Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Camada de Sa√≠da ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O modelo BERT tem 201 par√¢metros diferentes.\n",
            "\n",
            "==== Camada de incorpora√ß√£o (Embedding) ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== Primeiro Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Camada de Sa√≠da ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hBWGUmgUThZ"
      },
      "source": [
        "## Otimizador e taxas de aprendizagem ##\n",
        "\n",
        "Agora que carregamos nosso modelo, precisamos pegar os hiperpar√¢metros de treinamento de dentro do modelo armazenado.\n",
        "\n",
        "Para fins de ajuste fino, os autores recomendam escolher entre os seguintes valores (do Ap√™ndice A.3 do artigo de BERT ):\n",
        "\n",
        "1. Tamanho do lote (*batch size*): 16, 32\n",
        "1. Taxa de aprendizagem (*Adam*): 5e-5, 3e-5, 2e-5\n",
        "1. N√∫mero de √©pocas: 2, 3, 4\n",
        "\n",
        "Aqui vamos usar:\n",
        "\n",
        "1. Tamanho do lote: 32 (definido ao criar nossos *DataLoaders*)\n",
        "1. Taxa de aprendizagem: 2e-5\n",
        "1. √âpocas: 4 (veremos que provavelmente s√£o muitas ...)\n",
        "\n",
        "O par√¢metro ```eps = 1e-8``` √© ‚Äúum n√∫mero muito pequeno para evitar qualquer divis√£o por zero na implementa√ß√£o‚Äù (leia mais [aqui](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
        "\n",
        "Voc√™ pode encontrar a cria√ß√£o do otimizador *AdamW* em ```run_glue.py``` [aqui](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH48Pnl1UThZ"
      },
      "source": [
        "# Nota: AdamW √© uma classe da biblioteca huggingface\n",
        "# Provavelmente o 'W' √© de 'Weight Decay fix\" ('Corre√ß√£o de redu√ß√£o de peso \")\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - o padr√£o √©  5e-5, aqui usamos 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - o padr√£o √© 1e-8.\n",
        "                )"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Yk6BlpEUThZ"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# N√∫mero de √©pocas de treinamento. Os autores do BERT recomendam entre 2 a 4. \n",
        "# N√≥s escolhemos 4, mas vamos ver depois que isso pode estar causando overfit nos dados de treinamento\n",
        "epochs = 4\n",
        "\n",
        "# N√∫mero total de passos de treinamento √© [n√∫mero de batches] x [n√∫mero de √©pocas]. \n",
        "# (Note que n√£o √© o mesmo que o n√∫mero de inst√¢ncias de treinamento).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Criando o programador de taxa de aprendizagem (learning rate scheduler)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Valor padr√£o no run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xK0zVkdGUTha"
      },
      "source": [
        "## *Loop* de treinamento ##\n",
        "\n",
        "Abaixo est√° o nosso *loop* de treinamento. H√° muita coisa acontecendo, mas fundamentalmente para cada passagem em nosso *loop*, temos uma fase de treinamento e uma fase de valida√ß√£o.\n",
        "\n",
        "**Treinamento:**\n",
        "\n",
        "1. Descompacta nossas entradas (dados e r√≥tulos)\n",
        "1. Carrega dados na GPU para acelera√ß√£o (quando necess√°rio)\n",
        "1. Limpa os gradientes calculados na passagem anterior\n",
        "(no *pytorch*, os gradientes se acumulam por padr√£o (√∫til para RNNs), a menos que a gente limpe explicitamente)\n",
        "1. Passo *Forward* (avan√ßo), alimentando os dados de entrada pela rede\n",
        "1. Passo *Backward* (para tr√°s), ou retropropaga√ß√£o\n",
        "1. Informa a rede para atualizar os par√¢metros com ```optimizer.step ()```\n",
        "1. Rastreia vari√°veis para monitorar o progresso\n",
        "\n",
        "**Avalia√ß√£o:**\n",
        "\n",
        "1. Descompacta nossas entradas (dados e r√≥tulos)\n",
        "1. Carrega dados na GPU para acelera√ß√£o (quando necess√°rio)\n",
        "1. Passo *Forward* (avan√ßo), alimentando os dados de entrada pela rede\n",
        "1. Calcula a perda (*loss*) em nossos dados de valida√ß√£o e rastreia vari√°veis para monitorar o progresso\n",
        "\n",
        "*Pytorch* esconde todos os c√°lculos detalhados, mas comentamos o c√≥digo para apontar quais das etapas acima est√£o acontecendo em cada linha.\n",
        "\n",
        "No c√≥digo abaixo, definimos uma fun√ß√£o auxiliar para calcular a precis√£o."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSljX7FAUTha"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Fun√ß√£o para caluclar a acur√°cia das nossas perdi√ß√µes x r√≥tulos\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDjNSgJjUTha"
      },
      "source": [
        "Fun√ß√£o auxiliar para formatar o tempo decorrido (hh:mm:ss)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEsSXtJCUTha"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Pega o tempo em segundos e retorna como hh:mm:ss\n",
        "    '''\n",
        "    # Arredonda\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Formata como hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9Rur-k-UTha"
      },
      "source": [
        "Estamos prontos para come√ßar o treinamento!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uzk4DAAgUThb",
        "outputId": "014c103e-3598-48f4-b0be-71b427941102"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Esse c√≥digo √© baseado no `run_glue.py`\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Seta o valor 'seed' para tornar reproduz√≠vel\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Vamos guardar os valores de perda do treinamento e valida√ß√£o, acur√°ria e tempos de execu√ß√£o.\n",
        "training_stats = []\n",
        "\n",
        "# Medir o total do tempo de treinamento para toda execu√ß√£o\n",
        "total_t0 = time.time()\n",
        "\n",
        "# para cada √©poca\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Treinamento\n",
        "    # ========================================\n",
        "    \n",
        "    # Executa um passo inteiro em todo conjunto de treinamento\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== √âpoca {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Treinando...')\n",
        "\n",
        "    # Mede quando tempo a √©poca de treinamento demora\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reseta a perda total para esta √©poca\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Coloca o modelo em modo de treinamento.\n",
        "    # Essa chamada para `train` apenas muda o modo, mas n√£o executa o treinamento.\n",
        "    # as camadas `dropout` e `batchnorm` tem comportamento diferente durante o treinamento\n",
        "    # (veja mais: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # Para cada batch dos nossos dados de treinamento\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Atualiza progresso a cada 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calcula o tempo em minutos.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Imprime o progresso.\n",
        "            print('  Batch {:>5,}  de  {:>5,}.    Tempo: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Retira esse batch de treinamento do nosso dataloader. \n",
        "        #\n",
        "        # Agora que retiramos esse batch, tamb√©m vamos copiar cada tensor para a GPU usando o m√©todo `to`, se necess√°rio.\n",
        "        #\n",
        "        # `batch` cont√©m tr√™s tensores pytorch:\n",
        "        #   [0]: ids de entrada \n",
        "        #   [1]: m√°scaras de aten√ß√£o\n",
        "        #   [2]: r√≥tulos\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Sempre limpe qualquer gradiente calculado anteriormente antes de executar o passo de \n",
        "        # backward, pois o PyTorch n√£o faz isso automaticamente, j√° que acumular os gradientes √©\n",
        "        # importante para o treinamento das RNNs. \n",
        "        # (https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Executa o passo forward (avalia o modelo no batch de treinamento).\n",
        "        # Documenta√ß√£o para essa fun√ß√£o: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # Retorna n√∫meros diferentes de par√¢metros, dependendo de qual argumento foi passado e quais flags foram setadas.\n",
        "        # Aqui, vai retornar a perda (loss) e os \"logits\", sa√≠das do modelo antes da ativa√ß√£o\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        # Acumula a perda do treinamento de todos os batches ent√£o podemos calcular a m√©dia da perda no final. \n",
        "        # `loss` √© um Tensor contendo um valor √∫nico, a fun√ß√£o `.item()` apenas retorna o valor Python do tensor.\n",
        "        \n",
        "        # com a vers√£o nova do Transformers (4.x) aqui d√° erro\n",
        "        total_train_loss += loss.item()\n",
        "        \n",
        "        # Executa o passo backward para calcular os gradientes\n",
        "        loss.backward()\n",
        "\n",
        "        # Corta a norma dos gradientes para 1.0., para ajudar a prevenir o problema de \"exploding gradients\".\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Atualiza par√¢metros e passa uma etapa usando o gradiente calculado.\n",
        "        # O otimizador dita o \"update rule\", ou seja, como os par√¢metros s√£o modificados com base \n",
        "        # nos gradientes, taxa de aprendizagem, etc\n",
        "        optimizer.step()\n",
        "\n",
        "        # Atualiza taxa de aprendizagem\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calcula a perda m√©dia sobre todos os batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Mede quanto tempo levou essa √©poca\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Perda m√©dia do treinamento: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  √©poca de treinamento levou : {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Valida√ß√£o\n",
        "    # ========================================\n",
        "    # Ap√≥s a conclus√£o de cada √©poca de treinamento, vamos medir nosso desempenho em nosso conjunto de valida√ß√£o\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Executando Valida√ß√£o...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Coloca o modelo no modo de avalia√ß√£o, ou seja, as camadas dropout ter√£o comportamento diferente\n",
        "    model.eval()\n",
        "\n",
        "    # Vari√°veis de rastreamento\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Avalia os dados para uma √©poca\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Retira esse batch de treinamento do nosso dataloader. \n",
        "        #\n",
        "        # Agora que retiramos o batch, vaos copiar cada tensor para nossa GPU com o m√©todo `to`, se estamos usando GPU\n",
        "        #\n",
        "        # `batch` cont√©m 3 tensores pytorch:\n",
        "        #   [0]: ids de entrada \n",
        "        #   [1]: m√°scaras de aten√ß√£o\n",
        "        #   [2]: r√≥tulos\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Informa pytorch para n√£o n√£o se preocupar em construir o gr√°fico de computa√ß√£o durante o passo forward,\n",
        "        # j√° que precisa apenas no passo backprop (treinamento).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Passo Forward, calcula as predi√ß√µes logit.\n",
        "            # token_type_ids √© o mesmo que os \"segment ids\", que diferencia as senten√ßas 1 e 2 em uma tarefa com 2 senten√ßas\n",
        "            # Documenta√ß√£o da fun√ß√£o `model`: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Pega as sa√≠das \"logits\" do model, valores pr√©vios √† aplica√ß√£o da fun√ß√£o de ativa√ß√£o como a softmax.\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Acumula a perda da valida√ß√£o\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move os logits e r√≥tulos para CPU, se necess√°rio\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calcula a acur√°cia desse batch nas frases de teste, e acumula sobre todos os batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Imprime a acur√°cia final para a execu√ß√£o da valida√ß√£o.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Acur√°cia: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calcula a m√©dia da perda sobre todos os batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Mede quanto tempo levou a valida√ß√£o\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Valida√ß√£o perda (Loss): {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Valida√ß√£o levou: {:}\".format(validation_time))\n",
        "\n",
        "    # Grava as estat√≠sticas para esta √©poca.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Treinamento completo!\")\n",
        "\n",
        "print(\"Tempo total de treinamento {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== √âpoca 1 / 4 ========\n",
            "Treinando...\n",
            "  Batch    40  de    241.    Tempo: 0:00:14.\n",
            "  Batch    80  de    241.    Tempo: 0:00:28.\n",
            "  Batch   120  de    241.    Tempo: 0:00:42.\n",
            "  Batch   160  de    241.    Tempo: 0:00:57.\n",
            "  Batch   200  de    241.    Tempo: 0:01:11.\n",
            "  Batch   240  de    241.    Tempo: 0:01:27.\n",
            "\n",
            "  Perda m√©dia do treinamento: 0.49\n",
            "  √©poca de treinamento levou : 0:01:27\n",
            "\n",
            "Executando Valida√ß√£o...\n",
            "  Acur√°cia: 0.83\n",
            "  Valida√ß√£o perda (Loss): 0.40\n",
            "  Valida√ß√£o levou: 0:00:04\n",
            "\n",
            "======== √âpoca 2 / 4 ========\n",
            "Treinando...\n",
            "  Batch    40  de    241.    Tempo: 0:00:16.\n",
            "  Batch    80  de    241.    Tempo: 0:00:32.\n",
            "  Batch   120  de    241.    Tempo: 0:00:47.\n",
            "  Batch   160  de    241.    Tempo: 0:01:02.\n",
            "  Batch   200  de    241.    Tempo: 0:01:18.\n",
            "  Batch   240  de    241.    Tempo: 0:01:33.\n",
            "\n",
            "  Perda m√©dia do treinamento: 0.30\n",
            "  √©poca de treinamento levou : 0:01:34\n",
            "\n",
            "Executando Valida√ß√£o...\n",
            "  Acur√°cia: 0.84\n",
            "  Valida√ß√£o perda (Loss): 0.46\n",
            "  Valida√ß√£o levou: 0:00:04\n",
            "\n",
            "======== √âpoca 3 / 4 ========\n",
            "Treinando...\n",
            "  Batch    40  de    241.    Tempo: 0:00:16.\n",
            "  Batch    80  de    241.    Tempo: 0:00:31.\n",
            "  Batch   120  de    241.    Tempo: 0:00:46.\n",
            "  Batch   160  de    241.    Tempo: 0:01:02.\n",
            "  Batch   200  de    241.    Tempo: 0:01:17.\n",
            "  Batch   240  de    241.    Tempo: 0:01:33.\n",
            "\n",
            "  Perda m√©dia do treinamento: 0.19\n",
            "  √©poca de treinamento levou : 0:01:33\n",
            "\n",
            "Executando Valida√ß√£o...\n",
            "  Acur√°cia: 0.83\n",
            "  Valida√ß√£o perda (Loss): 0.57\n",
            "  Valida√ß√£o levou: 0:00:04\n",
            "\n",
            "======== √âpoca 4 / 4 ========\n",
            "Treinando...\n",
            "  Batch    40  de    241.    Tempo: 0:00:15.\n",
            "  Batch    80  de    241.    Tempo: 0:00:31.\n",
            "  Batch   120  de    241.    Tempo: 0:00:46.\n",
            "  Batch   160  de    241.    Tempo: 0:01:02.\n",
            "  Batch   200  de    241.    Tempo: 0:01:17.\n",
            "  Batch   240  de    241.    Tempo: 0:01:33.\n",
            "\n",
            "  Perda m√©dia do treinamento: 0.13\n",
            "  √©poca de treinamento levou : 0:01:33\n",
            "\n",
            "Executando Valida√ß√£o...\n",
            "  Acur√°cia: 0.84\n",
            "  Valida√ß√£o perda (Loss): 0.58\n",
            "  Valida√ß√£o levou: 0:00:04\n",
            "\n",
            "Treinamento completo!\n",
            "Tempo total de treinamento 0:06:21 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vyJO3kOUThb"
      },
      "source": [
        "Vamos ver o resumo do processo de treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "IQYHD9T8UThb",
        "outputId": "f17399fd-57cf-4238-a5a3-940c03bdbcf3"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Mostra n√∫meros com duas casas decimais\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Cria um DataFrame das nossas estat√≠sticas de treinamento\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Usa a √©poca como o √≠ndice da linha\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# For√ßar o agrupamento dos cabe√ßalho da coluna \n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Mostra a tabela\n",
        "df_stats"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.49</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:01:27</td>\n",
              "      <td>0:00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.30</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0:01:34</td>\n",
              "      <td>0:00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.19</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.83</td>\n",
              "      <td>0:01:33</td>\n",
              "      <td>0:00:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.13</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0:01:33</td>\n",
              "      <td>0:00:04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.49         0.40           0.83       0:01:27         0:00:04\n",
              "2               0.30         0.46           0.84       0:01:34         0:00:04\n",
              "3               0.19         0.57           0.83       0:01:33         0:00:04\n",
              "4               0.13         0.58           0.84       0:01:33         0:00:04"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guNi39XGUThb"
      },
      "source": [
        "Observe que, enquanto a perda de treinamento est√° diminuindo a cada √©poca, a perda de valida√ß√£o est√° aumentando! Isso sugere que estamos treinando nosso modelo por muito tempo e que ele est√° se ajustando demais aos dados de treinamento.\n",
        "\n",
        "(Para refer√™ncia, estamos usando 7.695 amostras de treinamento e 856 amostras de valida√ß√£o).\n",
        "\n",
        "A perda de valida√ß√£o √© uma medida mais precisa do que a precis√£o, porque com a precis√£o n√£o nos importamos com o valor de sa√≠da exato, mas apenas em que lado de um limite ele cai.\n",
        "\n",
        "Se estivermos prevendo a resposta correta, mas com menos confian√ßa, a perda de valida√ß√£o pegar√° isso, mas a precis√£o n√£o."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "J3OyoiaCUThb",
        "outputId": "8c2b788f-4c46-4192-f5c4-8eb09e602391"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Usando estilo\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Aumentando o tamanho e fonte \n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plotando a curva de aprendizagem\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Treinamento\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Valida√ß√£o\")\n",
        "\n",
        "# Adicionando t√≠tulos\n",
        "plt.title(\"Perda de treinamento e valida√ß√£o\")\n",
        "plt.xlabel(\"√âpoca\")\n",
        "plt.ylabel(\"Perda\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuUAAAGcCAYAAAB+/95qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3hUVfrA8e9MeiU9k0IJZUJJIYHg0lRKICC9ihTL2lDRn9hQd1d014INV1RWXBEFlSJFULrIioAmmNADSC/JJCEhvcxM5v7+gAxMMkACSSYk7+d5eELOvfeccye58M6Z95yjUhRFQQghhBBCCGEzalt3QAghhBBCiKZOgnIhhBBCCCFsTIJyIYQQQgghbEyCciGEEEIIIWxMgnIhhBBCCCFsTIJyIYQQQgghbEyCciFEvVixYgXh4eH8/vvv9dLe2bNnCQ8PZ86cOfXSXm0LDw9nxowZtu6GsDFrvwd9+/Zl8uTJ1bq+Pp+73bt307t3b/r27cv69evZvXs3cXFxdd6uEI2Fva07IISoO7///jtTpkyxKHN1dSUsLIzhw4czadIk7OzsbNS7W1NqaiqbN29m5MiRhIaG2ro7TcLvv/9OYmIi9957L56enrbujriKBQsWEB4eTseOHXn55ZcpLi7m4YcftnW3hLhlSFAuRBMwZMgQbr/9dhRFITMzk5UrV/LGG29w9OhR/vnPf9q6e7eU1NRUPvroI7p161anQfnevXtRq+XDTIDExEQ++ugjRo4cKUE5sH79elt3waoXX3wRNzc33N3deeyxxygsLMTPz8/W3RLiliFBuRBNQMeOHRk+fLj5+3vuuYdBgwaxbNkynnrqqVr5j7OwsBB3d/ebrqexKS8vR6/X4+LiUqPrnJyc6qhH4lbn6Oho6y5YFRgYaP67s7Mzzs7ONuyNELceGYYRoglyd3cnJiYGRVE4c+aMuXzt2rVMmDCBmJgYoqOjGTt2rNVRuYo81507d5rPnzp1qvn40qVLSUhIICIigvj4eBYsWICiKFXqycjI4K233mL48OHExcURGRnJ4MGDmTdvHuXl5dW+n127dnH33XcTFRVFjx49eO211yguLrZ6rqIofPPNN4waNYro6GhiYmKYPHkyv/3223XbmTNnDi+++CIAU6ZMITw83CLntyJ/d8eOHXz88cf079+fqKgo1q1bV+O2reUSV5SlpKQwadIkOnfuzG233cbLL79MUVGRxbnHjh1j5syZ3HXXXeaf56hRo1i2bJnV+woPD+fo0aO8/vrr9OrVi+joaO69916OHz8OwMaNGxk5ciRRUVH07duXJUuWWH2NduzYwQMPPEDXrl2JjIxk6NChfPvtt1XOq8iLPnbsGA8//DAxMTF06dKFJ598kqysLPN5M2bM4KOPPgKgX79+5tf8yrkCZ8+e5bnnnqNHjx5ERETQv39/3n//fUpKSqz20ZqTJ0/y3HPP0atXLyIiIujbty+zZs266u/RlcaOHUuPHj0wGo1Vjm3bto3w8HAWLFgAgMlkYu7cuUycOJGePXsSERHBnXfeySuvvMKFCxeq1der5ZTX1XOn1+v57LPPGD58ONHR0XTp0oVRo0axaNGiG64zJyeHV199lTvuuIOIiAjuuOMOXn311Wq/BkI0RjJSLkQTpCgKp06dAsDb2xuA2bNn85///IfevXvz1FNPoVar2bRpE0899RT/+Mc/mDhxokUd+/fvZ8OGDYwbN46RI0eayxcsWMCbb75J+/btmT59OiUlJcyfPx9fX98q/Th8+DAbN24kPj6eFi1aYDAY2LZtG++99x5nz57ltddeu+697Nmzh/vvvx83NzceeughPDw8WLt2LS+88ILV85977jl+/PFHBg4cyKhRo9Dr9axZs4YHHniAOXPm0K9fv6u2FR8fT1ZWFkuWLOHRRx+ldevWALRo0cLivFmzZmE0Ghk3bhxubm6EhYXddNsVUlNTefTRRxk1ahRDhgwhMTGR7777DrVabZGKlJiYyK5du7jzzjsJDQ2lpKSE9evX87e//Y2cnBweeeSRKnW/8MILuLq68sgjj5CTk8MXX3zBgw8+yJNPPsm7777L3XffzejRo/nuu+/4xz/+QZs2bejatav5+iVLlvDKK6/QuXNnHn30UVxcXNixYwczZ87k9OnTVX4mGRkZTJkyhf79+/P8889z6NAhlixZQmFhIfPnzwdg/PjxFBYWsmnTJl588UXz72t4eDgA586dY+zYsRQUFHDPPffQsmVLEhMT+fTTT0lOTmbBggXY21/7v7r9+/eb89XHjx9PYGAghw4dYuHChaSkpLBw4UIcHByuev2IESN47bXX2LZtG3369LE4tmrVKuzt7Rk6dCgABoOBzz//nAEDBtCvXz9cXFzYt28fy5cvJzk5meXLl9/QSHhdPXd6vZ6//vWvJCYm0qtXL4YNG4aTkxNHjhxh48aNTJo0qcZ1FhQUMGHCBE6dOsXo0aPp2LEjqampfPvtt/z2228sW7ZMPnUTTZMihGi0fvvtN0Wr1Spz5sxRsrOzlezsbCU1NVV5+eWXFa1Wq4wbN05RFEXZv3+/otVqlffee69KHVOnTlViYmKUgoICc5lWq1W0Wq2yfft2i3Pz8vKU6OhoZdCgQUpxcbG5PD09XencubOi1WqV3377zVxeUlKimEymKm0+++yzSvv27ZWMjIzr3uP48eOVTp06KcePHzeXlZWVKaNHj1a0Wq3y4Ycfmss3btyoaLVaZfHixRZ1GAwGZeTIkUqfPn2s9udKy5cvr3IflY8NGDDA4v5vpG2tVqu88MILFudqtVolPDxc2b17t0X5Qw89pHTs2FEpLCw0lxUVFVXpX3l5uTJp0iQlNjZW0ev15vIPP/xQ0Wq1yiOPPGLRhy+//FLRarVKTEyMkpaWZi7Pzs5WIiIilKefftpclpGRoURERCjTp0+v0u4///lPpX379srp06fNZX369FG0Wq3y448/Wpw7c+ZMRavVKseOHavSvzNnzlSpe/r06YpWq1W2bt1qUf7WW28pWq1WWbp0aZVrKhs6dKgycOBAi99xRbn8M1u+fPk1r79w4YLSqVMn5cknn7QoLygoUKKjo5VHHnnEXGYymZSSkpIqdSxdutTq62Ht96BPnz7KpEmTzN/X5XM3b968q/7bUF5efkN1vv/++4pWq1UWLVpkce6iRYsUrVarzJ49u0o9QjQFkr4iRBMwZ84cunfvTvfu3Rk+fDjLly+nb9++fPzxxwCsWbMGlUrFiBEjyMnJsfjTt29fioqK2L17t0Wd7du3p0ePHhZlv/76KyUlJUycONEih1qj0ZhHCq/k7OyMSqUCLo7I5ebmkpOTQ69evTCZTOzfv/+a95WdnU1KSgp9+/Y1j0bDxZzb++67r8r5q1evxs3Njf79+1vcY35+Pn379uXcuXOcPHnymm1Wx4QJE6rkkNdW2507dyY6Otqi7C9/+QtGo5Fz586Zy1xdXc1/Lysr48KFC+Tm5tKzZ08KCwvNaSlXmjx5svnnAZhHwfv27UtQUJC53MfHh7CwMIv+btiwAb1ez5gxY6z+DplMJnbs2GHRXkBAAIMHD65yL4D5k5xrMZlMbNmyhY4dO3LHHXdYHHvkkUdQq9Vs3rz5mnUcPnyYw4cPM2TIEPR6vUW/u3TpgqurK9u3b79mHV5eXvTt25eff/6Z/Px8i9ekpKTE4pMklUplzrUuLy8nPz+fnJwc833v3bv3uvddWV0+d2vWrKFZs2Y8/vjjVeq5ciJyTerctGkTPj4+jB8/3qK+8ePH4+Pjc92fmRCNlaSvCNEEjB8/noSEBFQqFS4uLrRq1QovLy/z8WPHjqEoCoMGDbpqHefPn7f4vlWrVlXOOXv2LIA5reNKbdq0qVJmNBqZN28e33//PadOnaqS/3plgGNNRT68tfbatm1bpezYsWMUFRVVeTNxpezsbIsA/0ZYu7622m7evHmVsoqfZW5urrmsqKiIjz76iHXr1pGenl7lGmuvbeW6K1Y6sbbKTLNmzSzeBBw7dgzA6puhCpV/h6p7L1eTk5NDcXGx1Z+1l5cX/v7+FnMmrKno95w5c666pn3lflszYsQINmzYwLp168zB5qpVq2jWrFmVlJa1a9fyxRdfkJqaisFgsDiWl5d33bYqq8vn7tSpU3To0OG6E49rUufZs2eJiIioklZkb29Pq1atOHjw4DXbEqKxkqBciCagZcuW1wwGFUVBpVLx2WefXXXd8sqBT01XE7HmrbfeYuHChQwePJhHH30UHx8fHBwcOHDgAO+++y4mk+mm27iSoij4+Pjw3nvvXfWcdu3a3XQ71ladqK22r7Wu/JWB0DPPPMPWrVsZN24ccXFxeHl5YWdnx//+9z8WLFhg9bW92hKM1VnLvqLtWbNmERAQYPWcykF4de+lPjzwwAP07t3b6rHqLMN4++234+Pjw6pVqxg/fjxpaWkkJSVx9913W+SIb9y4kaeffpqoqCheeuklgoKCcHJyory8nAcffLBe7rsunrv6fpaFaIwkKBdC0KpVK7Zt20ZwcLDVkbXqqhhRPX78ON27d7c4VjEieaXvv/+euLg4Zs+ebVFendSFyu1VdvTo0SplLVu25OTJk0RHR+Pm5latNiq7Mr2jJmqj7erKz89n69atDB8+vMpk2copJLWl4pMTb2/va74BvBFXe819fHxwc3Oz+rPOy8sjKyuLDh06XLPuli1bAhffkNxMv+3t7RkyZAhfffUVZ86c4YcffkBRFIvUFbj4O+/k5MRXX31l8cbW2vNRXXX53LVq1Yrjx4+j1+uvOQG1JnU2b96cEydOYDQaLUbLjUYjJ0+etPoJihBNgeSUCyEYNmwYAO+//77V5cuq8/E9QM+ePXF2dubrr7+2WI5Op9OxZs2aKuer1eoqI4PFxcXm5eOux8/Pj86dO7NlyxZOnDhhLtfr9VbrGDFiBCaTiffff99qfdW5z4pc7ZqmGdRG29VVMeJd+bXNzMy0uiRibRg0aBCOjo7MmTOH0tLSKscLCgrQ6/U3VPfVXnO1Wk2fPn04ePAgv/zyi8WxefPmYTKZ6N+//zXr7tixI1qtlsWLF1tNdTEajdVKpQHMAfiqVav4/vvvCQsLq5L/b2dnh0qlshg5VhSFuXPnVqsNa+ryuRs6dCh5eXl88sknVY5dWUdN6qyYV1H5d3Hp0qXk5ORc92cmRGMlI+VCCKKiopg2bRpz5sxhxIgRDBw4kMDAQDIzMzlw4AC//PLLdSddwsU846eeeopZs2Zx9913M2LECEpKSli8eLHVXNGBAweyZMkS/u///o8ePXpw/vx5li9fbpHvfj0zZsxg8uTJTJgwgYkTJ5qXRLT25iIhIcG8vvKBAwfo06cP3t7e6HQ6du/ezalTp/jpp5+u2V5kZCRqtZr//Oc/5OXl4erqSmhoaJXgqy7ari53d3d69uzJ6tWrcXZ2JjIyknPnzrFkyRJCQ0OrHWTWhEajYebMmfztb39j8ODBDBs2jJCQEHJycjhy5AibN2/mxx9/vKFdUCte23fffZehQ4fi5OREu3bt0Gq1TJ8+nR07dvD4449zzz330KJFC3bt2sXatWuJi4urMlJdmUql4u233+bee+9l2LBhjB49mrZt21JaWsqpU6fYtGkT06dPZ9SoUdftZ0WAv2DBAgoLC5k+fXqVcwYOHMiGDRu49957GTFiBEajkc2bN9doTfXK6vK5mzJlCj///DNz585l37599OrVC0dHR44ePcqJEyfMQXdN6nzwwQdZv349r732GgcPHqRDhw6kpqby3XffERYWxoMPPnjDr4UQtzIJyoUQADzxxBNERESwcOFCvvrqK4qLi/H19aVdu3a8/PLL1a7ngQcewNXVlS+++IL33nuPoKAgHnjgATw8PHjppZcszq3Ylnv9+vX89NNPBAUFMX78eCIjI685YfBKMTEx5rbmzZuHh4cHAwcOZMKECVZXnnjzzTe57bbbWLp0KZ9++ikGgwF/f386duzIM888c932goODeeONN/jss8949dVXMRgMjBw58rpBeW20XRPvvPMO7733Hlu2bGHlypW0atWKp59+Gnt7e/MGSLVt9OjRtGrVivnz57NkyRIKCgrw8vIiLCyMp556Cn9//xuqt0uXLjz77LMsXryYv//97xiNRp544gm0Wi0hISEsXbqUDz/8kNWrV1NQUEBgYCCPPPIIU6dOve4a5QAdOnRg5cqVfPrpp2zZsoXFixfj5uZGSEgII0eOrJISci0jR45k1qxZqNVq8ydQV7rrrrsoKipiwYIFzJo1yzwR9JlnnuG2226r0etypbp67hwdHZk/fz7z58/nhx9+4K233gIgIiLC4o1KTer08PDg22+/5cMPP2TLli2sWLECX19f7r77bqZNmyZrlIsmS6XU92waIYQQQtySTpw4wcSJE1m/fn21JsAKIapPcsqFEEIIUS1hYWEEBASwbt06W3dFiEZH0leEEEIIcU3p6emsWbMGZ2dnTp48ecOTdoUQVydBuRBCCCGuyWg0snDhQnJzc+ncubPV+RpCiJsjOeVCCCGEEELYmE1zyvV6Pe+88w69evUiKiqKcePGsXPnzmpfv2bNGsaMGUPnzp3p1q0bkyZNYu/evXXYYyGEEEIIIWqfTdNXZsyYwcaNG5kyZQotW7Zk5cqVPPTQQyxcuJCYmJhrXjt79mz++9//MmzYMMaPH09xcTGHDh0iKyurnnovhBBCCCFE7bBZ+srevXsZO3YsL774onkN07KyMoYMGUJAQABff/31Va9NTk7mnnvuYc6cOcTHx9dKfy5cKMJkqt+XwtfXnezswnptU4hbkTwrQlSPPCtCVI+tnhW1WoW3t5vVYzYbKV+/fj0ODg6MHTvWXObk5MSYMWOYPXs2mZmZBAQEWL32q6++IjIykvj4eEwmEyUlJbi5Wb/B6jKZlHoPyivaFUJcnzwrQlSPPCtCVE9De1ZsllOemppKWFhYlWA6KioKRVFITU296rU7d+4kMjKS999/ny5duhAbG0vfvn1ZvXp1XXdbCCGEEEKIWmezkfKsrCwCAwOrlFdsw5yZmWn1ury8PHJzc/nxxx+xs7Pj2WefxcvLi6+//prnnnsOFxeXG0pp8fW1zba+/v4eNmlXiFuNPCtCVI88K0JUT0N7VmwWlJeWluLg4FCl3MnJCbiYX25NcXExALm5uSxdupTo6GgA4uPjiY+P5+OPP76hoDw7u7DeP8bw9/cgK6ugXtsU4lYkz4oQ1SPPihDVY6tnRa1WXXUg2GbpK87OzhgMhirlFcF4RXBeWUV5aGioOSAHcHR0ZODAgRw6dIiioqI66LEQQgghhBB1w2ZBub+/v9UUlYolDa82ydPLywtHR0f8/PyqHPPz80NRFAoLZea5EEIIIYS4ddgsfaV9+/YsXLiQoqIii8mee/bsMR+3Rq1W06FDBzIyMqoc0+l02NnZ0axZs1rvr8Ggp6AgF6NRj8lUXit1ZmaqMZlMtVKXaLzs7Oxxd/fCxeXmVhgSQgghRMNls6A8ISGB+fPns2zZMvM65Xq9nhUrVhAbG2ueBJqWlkZJSQlt2rSxuHbWrFls376dnj17AlBYWMi6deuIiYnB2dm5VvtaUlJEQcEF3N2b4eTkg1pth0qluul67e3VGI0SlIurUxQFg0FPbu7FT5AkMBdCCCEaJ5sF5dHR0SQkJPDuu++SlZVFixYtWLlyJWlpabz55pvm81544QUSExM5fPiwuWzChAksW7aMadOmcd999+Hp6cny5cspKChg+vTptd7XwsI8vLz8cHSs3WBfiOtRqVQ4Ojrh5eVPXt55CcqFEEKIRspmQTnA22+/zQcffMD3339PXl4e4eHhzJs3jy5dulzzOhcXF7766ivefvttFi1aRGlpKZ06deKLL7647rU3orzcgIOD9YmnQtQHBwdHysuNtu6GEEIIcUtL1CWz+th6csty8XLyYlibBLppYm3dLQBUiqI0rO2MbORaSyLqdKfQaFrWepuSviJqoq5+D28FssybENUjz4oQV5eoS+abQ8sxmC6v/uegduCe9qPrLTBvkEsiCiGEEEIIUVdMiolSYxn5+gLOl2Sz8uiPFgE5gMFkYPWx9TbqoSWbpq8IIYQQQoimy6SYMJiM6Mv1lJXrKSsvM/9df+lPmeny9xbl5Xr0Jj1lxovn6CufY6q6H441F8py6/guq0eCclFn0tPTGDt2GC+99AqDBw+1dXeEEEIIcQMURUFvMlgEvJe/lpkDZ325oVLQXHY5cC43VC2vQeBcQa1S42TniKPa8eLXS39c7V3wcmpmLnNSX/p6xTkrj/5IkaHqBpPeTl619VLdFAnKm6hevbpW67xly1YTFBRcx71pXLKzz7Nq1XJuv/1O2rULt3V3hBBCNAGKomAwGSyC5suBr956+ZWjzdbKyy+PQNeEWqW+FDQ7XAqMnXC0c8TF3plmTp5Vjl0ZOF8MuB1wuuK6K4/bq258WWo7ldpqTvmwNgk3VF9tk6C8ifr731+z+H7p0m/JyEhn2jTLJSW9vLxvuA2NJoifftqOvX3T+jXLycnmiy8+IygoWIJyIYQQZtYCZ72parBcJXXDaBlYVznfpMdQbkCh+mt3VA6cK4JfZzsnK4HzlUGzk0XgXHG8IoC+2cC5LlVM5myoq680rWhJmA0cONji+61bfyIvL7dKeWWlpaXV3pxJpVLh5CRLSQohhLh1XAycK+U4myqnbBispG5UHDdUyYu+nO9cs8BZhcoi8L0yAPZ09LAIpi0CZ3XV8srH7dX2DTJwrmvdNLF008Q2yJWKJCgXV/XEEw9TWFjI88+/xJw5szl8+BATJ07hr399hLKyUr78cj6bNm3g/PlMfHx8GTRoCPfd96B5ZNxaTvnrr89k27atfPnlYt5/fxbJybtwcnIiIWEIU6dOw87Oztz+N98s5Jdffub06VOUlpbSqlUYkyffR58+/S362atXV8aOnUCHDp1YsOAzMjJ0tG/fkRkz/k7z5i345puv+O67JeTm5hIX142XX56Jp2czizq2b9/GwoVfcPToEezs7IiNjePxx58iNLR5ldfjH/94jffff5vU1AN4eHgyduzdTJx4LwDJybt48slHAXjjjVd5441XASxeg59+2siiRQs4deokrq5u9OzZm6lTn8TLq2HktAkhRENXOXC2HG0uswicLYPmMnPgbDlRsKxWAufL6RfWA2dzwGxfNee5ytcmHDg3VRKU28jOAzpW/HKc7LxSfD2dGHVHG7p30ti6W1Xk5l7g+eefZsCABBIS7iIwUIPJZOL556dz8OB+hg8fRfPmLTh8OJWvvppPZmYGL730yjXrNBqNTJ/+BJGR0Tz++FMkJf3O4sWLCAkJZeTIMebzvvtuMT173k58fAJGo4HNmzfy97/P4O23P6BHj14WdSYn72Lbtq2MHDkGo9HIwoVf8NJLzxIfn8Avv2xlwoTJpKefY9myxXz88b958cV/mK9du3YNb775Gj169GLq1CcpLi5m+fIlPPbYgyxY8A0+Pr7mc/Pz83jmmSfp06cf/foN4OefNzN37hxat25L9+49adUqjIcffox58z5h2LCRREfHABAREWVu6403XqVTp0imTn2SzMwMli9fQmrqAT777Cv5ZEEIcUMa4oYoiqJgNBkrjSJb+WrSozdWHm2ulKJhJXWjpoGzo52DZY7ypYmCHo7u5mOVJwlePLfSdZUmGTpI4CxqiQTlNrDzgI4v1x1Cf2njoOz8Mr5cdwigwQXm589nMWPG3xkyZLi5bP36H9m9+w8++eRzOnWKMJcHB4fwn/98xMSJ99KyZaur1llaWkpCwl1Mnnw/ACNGjOGBBybyww/fWwTl3367HCeny6kyo0eP54EHJrJkyddVgvIzZ07z7bfLCQy8+PrZ29szd+4c1q79ga++WoyjoyMAOTk5bNq0nueeewl7e3uKi4v58MP3GDVqLE8//by5vn794pk8eRxLlnzD1KnTzOWZmRm88sq/iI+/OClkyJDhjBkzhB9//J7u3Xvi4+NL9+49mTfvEyIioizSgYxGI3PnzqFtWy1z5nxq7lN4eHtmznyZNWtWMmbM3df5iQghhKXKG6JcKMvlm0PLAa4bmFcOnCsHzVXTL649UbDy9TcSOFumXzhVCpwvB81X5jBXzn12snOSwFncciQovwnb96Xz6970Gl93LC0PY7nlP1R6o4kv1qbyy+60GtfXKyqInpFBNb6uOpydnUlIuMuibOvWnwgLa0NISCi5uZfX9uzatRsAKSm7rhmUAwwfPsri+6ioGDZsWGtRdmVAnp+fj8lkIioqhs2bN1Spr1u328wBOUDHjhffLMTHDzQHvxXlmzdv4Pz582g0GpKSfqewsJC+feMt7sXV1Y22bbWkpPxh0Y67uzv9+w80f+/g4ECHDp1ISzt3zfsFOHToIBcu5PDQQ1Mt+tS3bzwff/xvduzYLkG5EKLGVh9bb3VDlMWHV3Aw+4g5PaPqaLMBvUmPSan+ztIqVDhcCo4rp1+4ObhZ5jCrLVM6quQ2qy2DaAmcRVMnQbkNVA7Ir1duS/7+AVVWTzl79gwnT55gyJD+Vq+5Mri1xsXFtUpOt4eHBwUF+RZl27dv48svP+fo0SPo9ZeXY7L2j/aVATlcDJ4vlgdaLS8oyEej0XD27GkAHn/8Iat9DQ4Osfg+ICCwSvseHp4cO3bU6vVX0ukuvoFr0aKlRblarSY0tDkZGTV/gyeEaNrSizKuuvFJWbme43knLQLiisC5IiCukgt9ZWqHfeXA2REHtYMEzkLUEQnKb0LPyBsboX7uk+1k55dVKff1dOKFiQ1jWZ4KV45WVzCZTGi14Uyd+qTVayoHspXZ2amv2+6ePSnMmDGd6OgYpk9/AV9fP+zt7Vm7dg2bNlXdDlettrNSy9XLufSRqsl08esrr/zL6vKPlXO8r1afojS8N1RCiMYpryyfXRm7SdIlc6bw6p+uejt58VqPGfXYMyHEzZCg3AZG3dHGIqccwNFezag72tiwV9UXEhLKiRPHiYu7rc7a2Lp1C46Ojrz//kcWqR5r166p1XZCQkIB8PX1Iza2ehsqXXDMUiAAACAASURBVJ/1USSN5uIbuNOnT9G58+U3X4qicPbsGcLCbo2fvxCi/pUaS9mTdYBEXTKHLxxFQaGlR3PGtBuGWqVm5dEfG+yGKEKI6pGg3AYqJnPeCquvWHPnnf3YuXM769b9wKBBQyyOFRcXY2dnd9OriKjValQqFSbT5Tcu6elpbNu29abqraxbt7/g5ubGwoVfEBXVuUqqTm5ubo2XKnRxcQGgsNBy/dP27Tvi7e3DqlXfMWjQEBwcHAD4+eefyMrKZOLEKTdxJ0KIxqbcVE5qzhGSMlLYk3UAg8mAr7MPCa36EhcYQ6BbgPlcF3vnBrf6ihCiZiQot5HunTT0jg7GaKz+BJuGIiHhLn76aRNvvPEqSUm/06lTJEajgZMnT7BlyyY+/3yRxfreN6JHj14sWfI1zzwzjfj4gVy4cIEVK5YREtKcY8f+rKU7uZhj/vTTz/P66zN58MEp9OsXj6dnM3S6dH799X/07n0nDz/8WI3q1GiC8PRsxqpVy3F1dcXZ2YWOHSMIDg5h6tRpvPHGq0yb9gj9+w8gMzOD775bQuvWbRg6dGSt3ZcQ4takKAqnC86SqEtmV8ZuCg1FuNm78pegrnTTxBDm2dJqTndD3hBFCFE9EpSLGrOzs2PWrPf59tuFbNy4jp9/3oyLiyshIaFMmnQf/v7+N91Gly5xzJjxdxYt+pIPP3yfoKBgpk6dRnp6Wq0G5XDxTYafnz+LFi1g0aIFGI1G/P0DiYnpQv/+A2pcn729PX/726vMnfsh77zzJuXl5bz00isEB4cwePBQHB0d+frrL/n443/j5uZGfHwCjz46TdYoF6IJO1+STZIuhcSMZDKLz2OvtifSryPdAmPo6BuOvVr+uxaisVMpMkMNgOzsQvOkv8p0ulNoNC2tHrsZ9vbqW3KkXNhGXf0e3gpk9E80RoWGIpIz9pKUkczxvFOoUNHOqzVxmlhiAiJwsXepcZ3yrAhRPbZ6VtRqFb6+7laPyVtvIYQQop7oyw3sz04lUZfMgexDmBQTQW6BDG8ziLjAGLydazaHRQjReEhQLoQQQtQhk2LiaO5xEnUppGTuo7S8lGaOnvRp3otugbGEuAfJ2t9CCAnKhRBCiLpwrjCdJF0KSRkp5Jbl4WTnSIx/FHGaGLTebVCrrr9ngxCi6ZCgXAghhKglF0pzL27sk5HCucJ01Co1HX3CGdX2LiL9OuJo53j9SoQQTZIE5UIIIcRNKDGWsjtzH4kZKfx54RgKCmGeLRinHUFsQBQejtYndQkhxJUkKBdCCCFqqNxUzsGcwyTpUth7/gAGkxE/F18GtepHnCaGANebXxpWCNG0SFAuhBBCVIOiKJzMP02iLoXkzD0XN/ZxcKV7UDe6aWJo5dlCJmwKIW6YBOVCCCHENWQWZ13a2CeF8yXZOKjtifLrRJwmho4+4dip7WzdRSFEIyBBuRBCCFFJgb6QPzL3kKRL4WT+aVSo0Hq3IaFVPzr7R+Bi72zrLgohGhkJyoUQQghAX65n7/mDJOmSOZhzBJNiIsQ9iJFt76JrYGe8nJrZuotCiEZMgnIhhBBNlkkxceTCMZJ0KezO2kdpeRleTs3o1/x24jQxhLgH2bqLQogmQnYuELVi7do19OrVlfT0NHPZmDFDef31mTd0bW376KMPiI+/nX/96xXy8/OYNGksf/55uM7aE0I0XIqicLYgjRVHf+Bv299gzu7P2J21n9iAKJ6KeYR/9niREW0HS0AuhKhXMlLeRD3//NMkJyexZs0mXFxcrJ4zffoTHDiwj9WrN+Lk5FTPPaw9xcXFrFr1HQ89NJWNG9dz1139ad++A23atLN114QQ9ehCaS5JGSkk6VJIK9Jhp7Kjk2974jQxRPh2wNHOwdZdFEI0YRKUN1Hx8QPZsWMbv/76P+LjE6ocv3Ahhz/+SGLAgEE3HJB/881y1Grbfxjj6OjIokXL0GiCGD9+IufPZ+Hj49sg+iaEqFvFhhJ2Z+0jUZfM0dwTKCi0btaS8dqRxAZG4e7gZusuCiEEIEF5k9W79524uLiyefMGq0H5li2bKS8vZ8CAqseqy9GxYWwnbW9vj0Zz+WNoPz/Z1EOIxsxoMnIg+zBJumT2ZadiNBkJcPXjrrB4ugbG4O/qa+suCiFEFRKUN1HOzs707n0HP/+8mfz8fDw9PS2Ob968AV9fX5o3b8m7777FH38kkpGRgbOzM7GxXXn88acICgq+ZhtjxgwlJqYLL78801x2/PgxPvjgHfbv30ezZs0YPnyU1SB527atrF69kiNHDpOfn4e/fwCDBw9l8uT7sbOzXBN4//69fPHFfzlwYC/l5eWEhjZn1KhxDB06AoDk5F2sWLGUgwcPcOFCDt7ePvTp04+HH34MJyfLZc127Urk88//w5Ejh3FwcKRr12489tiTBAeH1OTlFULUM0VROJF/6uLGPhl7KDIW4+7gRq/g2+imiaWFR6hs7COEaNAkKLeRRF0ya46vJ6c0F28nL4a1SaCbJrZe+xAfn8DGjevYuvUnhg0baS7X6dLZv38vY8bcTWrqAfbv30v//gPx9w8gPT2NVauWM23aIyxatAxn5+qv1ZudfZ4nn3wUk8nEpEn34uzswurVK62mx6xd+wMuLq6MHz8RV1cX/vhjF//9738oKiri8cefMp/32287mDFjOv7+gYwbdw8+Pj4cPXqUHTt+NQflW7ZspqysjJEjx+Lp6Ulq6gG++24JGRkZ/Otfs8x1JSX9zrPPPknz5i158MGpFBcXsWzZt0yd+lcWLPgWb2/vG3mZhRB1KKMok6SMFBJ1KWSX5uCgdiDavxPdNLG0924nG/sIIW4ZEpTbQKIumW8OLcdgMgBwoSyXbw4tB6jXwDwu7ja8vLzZvHmDRVC+efMGFEUhPn4gbdq0pU+f/hbX9ex5O48+ej9bt/5EQsJd1W7v66+/JC8vl//+dyHh4e0BGDRoCBMmjKxy7syZ/7IYxR4xYgzvvPMGK1cu46GHpuLo6Eh5eTnvvfcWAQGBzJ//Ne7u7ubzFUUx//2JJ/7P4s3D8OGjCAlpzrx5H6PT6dBoNAB88sm/8fLyYu7cz/Hw8ADgttt68Oij97No0QKmTXu62vcqhKg7+foC/si4uLHPqYIzqFDR3qcdd4XFE+3fCWfZ2EcIcQuSoPwm/J7+BzvTk2p83Ym80xgVo0WZwWTg69Tv2JGWWOP6ugfFcVtQlxpfZ29vT9++/Vm1ajnnz5/Hz88PgM2bNxIa2pyOHSMszjcajRQVFRIa2hx3dw+OHDlUo6B8587tREZGmwNyAG9vb+LjB7Fy5TKLc68MyIuLi9DrDURHx/D99ys4deok7dppOXLkEOnpaTz99HMWATlg8TH1lQF5SUkJZWVlREZGoSgKf/55CI1Gw/nz5/nzzyNMnny/OSAHiIiIpFOnSHbu/FWCciFsqKxcz96sAyRmJHMo509Mionm7sGMajuEroGdaebkef1KhBCiAZOg3AYqB+TXK69L8fEJrFixjC1bNjJu3D2cPHmCo0ePcP/9DwFQVlbKwoULWLt2DVlZmRYj0IWFhTVqKyNDR2RkdJXyFi1aVik7fvwYn302l+TkJIqKiiyOFRVdbDct7RwAYWFtrtmuTqfj88//w6+//kJBQb7FsYp70OnSr9qXli1bsXnzxmu2IYSofeWmco5cOEZiRjK7s/ajL9fj7eRF/xZ3EBcYQ7C7xtZdFEKIWiNB+U24LajLDY1Q/237G1woy61S7u3kxf/FPlobXau2yMhogoJC2LRpPePG3cOmTesBzCuyzJ79DmvXrmHs2AlEREReGpFWMXPmSxYBem0qKChg2rSHcXV1569/fZSQkFAcHR05cuQQc+fOwWQyVbuu8vJynn76MQoK8pk4cQotW7bC2dmF8+ezeP31mXV2D0KIG6MoCmcKz5GkS2FXxm7y9QW42DsTF9iZuMBY2ni1Qq2S5UyFEI2PBOU2MKxNgkVOOYCD2oFhbW58+cGb0b//ABYu/IKzZ8/w008bCQ/vYB4xrsgbvzJ1o6ysrMaj5ACBgRrOnj1Tpfz06VMW36ek/EFeXh6vv/4OnTtfzrGvvONnSEgoACdOHCM2tqvVNo8fP8qZM6d5+eWZDBo0xFyelPSbxXkVSyZW7ktFWUXeuRCibmSX5JCUsZskXTK64kzsVHZE+HWgW2AMnXzb4yAb+wghGjkZbrCBbppY7mk/Gh9nL+DiCPk97UfX++orFQYMGATARx/N5uzZMxZrk6utrFywfPkSysvLa9xO9+492bdvD4cPHzKXXbhwgU2b1lmcV7Gpz5Wj2AaDoUreebt24Wg0QSxZ8k2VNwkV11rrv6IoLFu22KLMz8+Pdu20rF27xqKugwf3s3//Xrp371WTWxVCVEOxoZhfz/3G+3/M5R8732LN8fW4ObgxIXwUb/b6Ow9HTqFzQKQE5EKIJkFGym2kmyaWHqFdMRqrn4pRV8LCWtO2rZZff/0FtVpNv34Dzcd69OjFhg1rcXNzp1WrMA4c2MeuXYk0a9asxu3cc8+9bNiwlunTH2fMmLtxcnJm9eqVBAYGUVj4p/m8yMgoPDw8ef31mYwZMx6VSsWGDWupnGliZ2fHM8+8wIwZz3D//RMZPHgI3t4+nDx5nMzMTN544x1atmxFSEgoH3/8AVlZmbi5ubF16xYKCgqq9O+xx57i2WefZOrUB7jrrmEUFRWxbNlifH39mDTpvhrfrxCiKoPJyIHsQyTpktl/PhWjUk6gawBDWycQF9gZXxcfW3dRCCFsQoJyAcCAAQkcPXqEmJgu5lVYAJ566lnUajWbNq2jrExPZGQ0H3zwMdOnT6txG35+fnz44afMnv02CxcusNg86K23/mk+r1kzL95+ezYfffQBn302Fw8PTwYMGETXrt2YPv0Jizq7d+/Fv/89ly+++IzPP/8UAK02nFGjxgEXV5iZNWs2H3zwDgsXLsDJyZHevfswevQ47rtvgkVdcXG38e67H/L5558yb95cHB0dLm0e9JSsUS7ETTApJo7nnSJRl0xy5l5KjCV4OLpze2gP4jQxNHcPkY19hBBNnkqRmW4AZGcXYjJZfyl0ulNoNFVX5bhZ9vbqBjFS3liUlJQwZcp4PvvsK7y8vGzdnVpXV7+HtwJ/fw+ysqp+uiEaNl1RBom6FJIyUsgpvYCj2oFo/0i6aWII924rG/vUAXlWhKgeWz0rarUKX193q8dkpFw0Gi4uLrRt245ff/0fQ4YMt3V3hGiS8sry+SNjN4kZKZwpOIcKFR18tAxtPZAov04421fdwVcIIYQE5aKRWL58Kfb29uzbt5eYGOsrsQgh6kapsYw9WftJykjhUM6fKCi08AhlTLthxAZE08zJ4/qVCCFEEydBuWgUkpOT2LHjV9q2bUd8/MDrXyCEuCnlpnIOXThKki6ZPVn70ZsM+Dp7M7BVX+ICY9C4Bdi6i0IIcUuRoFw0Cq+//o6tuyBEo6coCqcLzpo39ikwFOJq70K3oC50C4yldbOWMmFTCCFukATlQgghrul8SQ5JuhSSMpLJKM7CXm1PpG8H4jSxdPQNx0Et/5UIIcTNkn9JhRBCVFFoKCIlcy+JuhSO550EoJ1Xa/q3uIPO/pG4OrjYtoNCCNHISFBeTYqiyMeywmZk5VJRHwzlBvZlp5KkS+FA9iHKlXI0boEMbz2IrprO+DjLev1CCFFXbBqU6/V6/v3vf/P999+Tn59P+/btefrpp+nevfs1r5szZw4fffRRlXI/Pz+2b99e6/20s3PAYCjD0dG51usWojoMBj12dvIeWtQ+k2LiaO4JknTJpGTto8RYSjNHD+4M7UmcJpZQ9yAZkBBCiHpg0//lZ8yYwcaNG5kyZQotW7Zk5cqVPPTQQyxcuJCYmJjrXv/aa6/h7Hw5UL7y77XJ3b0ZubnncXNrhrOzC2q1nfwnJeqFoigYDHpyc7Pw8JBRSlF70gp1JGWkkKRL4UJZLk52jnT2j6SbJhatdxvUKrWtuyiEEE2KzYLyvXv38uOPP/Liiy9y3333ATBixAiGDBnCu+++y9dff33dOgYNGoSnp2cd9xRcXNywt3egsDCXoqI8TKbyWqlXrVZjMsmOnuLa7Ozs8fDwxsXFzdZdEbe43LI8dmXsJkmXwtnCNNQqNR19tIxoO5gov4442jnauotCCNFk2SwoX79+PQ4ODowdO9Zc5uTkxJgxY5g9ezaZmZkEBFx7nVtFUSgsLMTNza3OR64dHBzx9q7ddXdlO2QhRF0rNZayO2s/SboUDl84ioJCK88WjNUOp0tANB6O1rd7FkIIUb9sFpSnpqYSFhaGm5vl6F9UVBSKopCamnrdoPzOO++kuLgYNzc3Bg4cyAsvvICXl1dddlsIIRq8clM5qTlHSNQls/f8QQwmA37OPiS06kecJoZAV39bd1EIIUQlNgvKs7KyCAwMrFLu73/xP4vMzMyrXuvp6cnkyZOJjo7GwcGB3377jSVLlnDw4EGWLVuGo6N8BCuEaFoUReFk/hmSMpL5I2MPhYYi3Bxc6R7UlThNLGGeLWQujBBCNGA2C8pLS0txcHCoUu7k5ARAWVnZVa+99957Lb5PSEigXbt2vPbaa6xatYpx48bVuD++vrb5CNff38Mm7Qpxq5FnxTpdQSbbTiWy7VQiusIsHOwc6BocRe+W3eis6Yi9rNrT5MizIkT1NLRnxWb/Wjs7O2MwGKqUVwTjFcF5dU2YMIF33nmHnTt33lBQnp1diMlUv2tBS065ENUjz4qlQn0Rf2TuIUmXzIn806hQ0c67Df3b30nngAhc7C9u7HMhp8TGPRX1TZ4VIarHVs+KWq266kCwzYJyf39/qykqWVlZANfNJ69MrVYTGBhIXl5erfRPCCEaEn25gX3nD5KUkcyB7MOYFBMh7kGMaDOYroGd8XaW+TRCCHErs1lQ3r59exYuXEhRUZHFZM89e/aYj9eEwWAgPT2diIiIWu2nEELYikkx8eeF4yRmJLM7cx+l5WV4OTWjX/PbidPEEOIeZOsuCiGEqCU2C8oTEhKYP38+y5YtM69TrtfrWbFiBbGxseZJoGlpaZSUlNCmTRvztTk5Ofj4+FjU9/nnn1NWVkbv3r3r7R6EEKIunCtMJ1GXzK6M3eSW5eFs50xMQBTdNDG09WotG/sIIUQjZLOgPDo6moSEBN59912ysrJo0aIFK1euJC0tjTfffNN83gsvvEBiYiKHDx82l/Xp04fBgwej1WpxdHTk999/Z8OGDXTp0oUhQ4bY4nZqZOcBHSv+d4yc/DJ8PJ0YdUcbunfS2LpbQggbulCay66M3STqkkkr0qFWqenkG87odkOJ8O2Ao13VifFCCCEaD5tOy3/77bf54IMP+P7778nLyyM8PJx58+bRpUuXa143dOhQkpOTWb9+PQaDgZCQEB577DEeeeQR7O0b9koDOw/o+HLdIfTGizt5ZueX8eW6QwASmAvRxJQYS0jJ3E+SLpk/c4+joBDm2ZLx2hHEBkTj7ii7uAohRFOhUhSlfpccaaDqa/WV5z7ZTnZ+1eUefT2deOexnnXevhC3osa0ooTRZCQ15wi/65LZd/4gRpORABc/4jQxxAXG4u/qa+suiltYY3pWhKhLsvqKsBqQX6tcCHHrUxSFE/mnSdIl80fmHooMxbg7uNEz+Da6aWJo6dFcNvYRQogmToLyeubr6WQ1AHdysKOo1ICbs+SNCtFYZBRnkaRLIUmXzPnSHBzUDkT7dyIuMIYOPlrs1Ha27qIQQogGQoLyejbqjjYWOeUAapWKMkM5L837jbF3tqVHpAa1jJoJcUsq0BfyR8YeEjOSOZV/BhUqwr3bMjgsnmj/TjjbO9u6i0IIIRogCcrrWcVkzsqrr4T4ubFw42Hmr03ll71pTIrX0iKwYW3/KoSwTl+uZ2/WARIzUkjNOYJJMRHqHszItnfRNbAzXk7NbN1FIYQQDZxM9LykviZ6XqnyJAOTorB9XzrLfj5GUamBfl1CGdGrNa7O8t5JNG0NcfKaSTFx+MJRknQp7M7aR1m5Hm8nr0sTNmMIdpfVlET9a4jPihANkUz0FNekVqnoHRVMTDt/VvxynJ92nSUpNZNxfdvyl46BMhFMCBtTFIWzhekk6ZLZlZFCnr4AF3tnugR0ppsmhjZeYbKxjxBCiBsiQXkD5O7iwJSB4fSOCmLRxsN8tuYg2/akMXFAOCF+sm6xEPUtp/QCu3S7ScxIJr0oAzuVHRG+7YnTxBLh2x4H2dhHCCHETZL0lUsaQvqKNSaTwi9701i+9Ril+nLi45ozrGcrnB3l/ZRoOmzxMWOxoYSUrL0k6VL4M/c4AG2atSJOE0tsQBRuDq712h8hqkPSV4SoHklfETWmVqu4s3MIXbT+fLf1GOt/P83vBzO4u187uob7S0qLELXIYDJyMPsQiboU9p8/iFEpJ9DVn6GtB9I1MAY/Fx9bd1EIIUQjJUH5LcLD1ZH7B3egd3QwizYcZu6q/XRq5c098VqCfCWlRYgbZVJMHM87RZIumeTMvRQbS/BwdKd3aHe6BcbS3CNE3vwKIYSoc5K+cklDTV+xxmRS+DnlHCt+OY7eUE7CbS0Y0qMVTg6yEYlonOriY0ZdUSZJumSSMlLILr2Ao9qBaP9IumliCPduKxv7iFuSpK8IUT2SviJqhVqtol+XULq2D2DplqP8uPMUvx3QMaG/lph2fjKqJ8RV5JUV8EfmbpJ0yZwuOIcKFe192jGk9UCi/DrhbO9k6y4KIYRooiQov4U1c3PkoaEduT06iEWbjvDRin1EtfHlnv7tCPCWSWhCAJSV69mTtZ9EXTKHcv5EQaGFRwij2w2lS0BnmjnJJl1CCCFsT9JXLrmV0lesMZab+OmPs6z69QTl5QqD/9KCwX9piaOktIhGoKbPSrmpnMMXjpKoS2HP+f3oy/X4OHvTLTCGOE0MGrfAOuytELYj6StCVI+kr4g6Y2+nZmC3FnTrEMiSLX+yevtJdh7QMTFeS1QbP1t3T4g6pygKZwrOkZiRzK6M3RToC3G1d7kUiMfSullL2dhHCCFEgyVBeSPj7eHEo8MjuD06h683HeGDZXuJaefHhP7t8GvmYuvuCVHrsktySMpIIVGXQkZxJvYqOyL8OtJNE0NH3/Y4qOWfOSGEEA2fpK9ccqunr1hjLDexMekMq7efAAWG9GjFwG4tcLCX0UJxa0jUJbP62Hpyy3LxcvJiWJsEumliKTIUk5y5lyRdMsfyTgLQ1iuMboGxxARE4iob+4gmStJXhKiehpi+IkH5JY0xKK+QnVfK4i1/8sfhLAJ9XJk0QEunVrIJimjYEnXJfHNoOQaTwVxmr7IjyE1DWpGOcqUcjWsA3TSxdA2MwdfF24a9FaJhkKBciOppiEG5fK7bBPg2c+bxkZHsO57N15uO8N7i3XRtH8Ddfdvi4+ls6+4JYdXqY+stAnIAo1LO2cI0+jTvRTdNLKHuwbIEqBBCiEZBgvImJLK1L//8azfW/X6aH3eeYt+xbIb1akV81+bY20lKi7ANRVHI0+dzrlBHWmH6xa9F6Vwoy7V+Pgqj2w2t514KIYQQdUuC8ibGwd6OYT3D6N5JwzebjrDs52Ns36djUryW9i3l439Rt8rK9aQX6ThXmE5a4eWvRcZi8zleTs0IcQ8iuySH0vKyKnV4O3nVZ5eFEEKIeiFBeRPl7+XCU2Oj2f3neb7ZfIS3v03hL50CGd+nLc3cZVdDcXNMionzJTkXR76LKkbA0zlfkoPCxbkbjnaOhLhp6BwQSbC7hhC3IELcNeZJmtZyyh3UDgxrk2CTexJCCCHqkgTlTVzndn50aOXN2p2nWPf7KfYcPc+IXq3p2yUEO7WktIjrKzIUm9NOzhWmk1akI61Ih75cD4AKFf6uvoS4B9NNE0uIexAh7kH4OHtfc93wbppYAKurrwghhBCNjay+ckljXn2lujJyivl60xH2n8gh1N+dyQO1tAuVVAFxkdFkJKM463LqSdHFr7lleeZz3BxcL414BxHsfnHkO8gtEEc7x5tqu6E9K0I0VPKsCFE9svqKaNACfVx5elw0fxzO4tuf/uTNRcn0jNQw9s62eLrdXFAlbh2XJ15ezvs+V5hORnEW5Uo5AHYqOzRuAWi921wMwN00hLgH4enoIauhCCGEEDdAgnJhQaVS0bV9AJGtfVm94wQbE8+QcuQ8o+9ozR2dQ1CrJeBqTMrK9aRdWu2kYvWTyhMvvZ28CHHXEOHXgRA3DcHuQQS6+mOntrNhz4UQQojGRYJyYZWTox1j72xLz4ggFm08zMKNR/hlbzqTB4TTOtjT1t0TNXRx4mX25ZHvS5Mvr5x46WTnSLBbEJ0DIs1538FugbI7phBCCFEPJKf8EskpvzpFUUhMzWTxlj/JL9Rze+dgRt/RBncXB1t3TVhRaCiyWG7wXFE66YU69JdWMTFPvKyU+329iZe2dKs8K0LYmjwrQlSP5JSLW5JKpeK2joFEtfHl+19PsHnXWf44nMWYO9vQKyoIteQQ20SViZeXcr/z9Pnmc9wd3Ah2D6JnyG0Eu9XexEshhBBC1C4JykW1uTjZc3e/dvSKvJjSsmDdIbbtSWPSgHBaajxs3b1GS1EUcsvySCu6HHinFerQFWdiUkwA2Kvs0LgF0t6nnXnN72D3IDwd3WXipRBCCHELkPSVSyR9pWYURWHHfh3Lfj5KQYmBvjGhjLw9DFdnSWm5GaXGMtKLMi5tunN5BLzYWGI+p2LiZfClvO8Q9yACXPwa9cTLW/lZEaI+ybMiRPVI+opoNFQqFT0jg4hp58fKX06wJeUsSYcyGNunLT0iNDI6ex0VEy+v3HDn4o6X2eZzKiZexgZEmXO/g900uDq42LDnQgghhKgLMlJ+iYyU35xTugIWbTzMsbR82oU2Y/KAcEIDrL8TbGouTry8vOTgucKLAhQ5qQAAIABJREFUO14arph4GeDqd3Hk2+3yCLiPs1eDnXhZ3xrTsyJEXZJnRYjqaYgj5RKUXyJB+c0zKQq/7k3nu63HKC410r9rKMN7heHi1DQ+kDGYjGQUZVbJ/a488fLiqLfGvPqJxi0QRztJ+7mWxvasCFFX5FkRonoaYlDeNKIlUS/UKhW3RwcTq/Vn+f+OsSnpDL+nZjC+b1tu6xDYaFJaKiZeVt5u/poTL92DCHaTiZdCCCGEsE6CclHr3F0cuDehPb2jglm48TDzVh9k2550JsZrCfZzs3X3auTixEvLvO9zhTpKqky8DCLSr6M5AG/sEy+FEEIIUbskfeUSSV+pGyaTwv92n2P5/45TZihnQFxzhvZshbNjw3o/aFJMZJVkm0e/0y6ln5wvzTGf42znRHDFqieXcr9l4mX9aArPihC1QZ4VIapH0ldEk6NWq+gTG0qX9gF89/Mx1v1+mt8OZjChXzu6hPvbJJWjUF9EWlG6eeWTc4XppBdlVJp46U9zz1D+EhRHyKXRbx9nb0k9EUIIIUSdkKBc1AtPV0ceuKsDvaODWLjhCJ+s2k9EmA8T47UE+rjWSZsVEy/PXbHmd1phOnn6y++MKyZe9g75i3kEXCZeCiGEEKK+SfrKJZK+Un/KTSa2JJ9j1bbjGIwmEm5ryV3dW+LkcGM52FdOvLwy9zujOMti4mWQW6B5ucGK3G9PR9mJ9FbQVJ8VIWpKnhUhqkfSV4QA7NRq4rs2J659AEt/PsoPO07y2wEd9/TX0rmd3zWvLTWWklax4+UVG+9cOfHSx9mbEHcNUX6dzKkn/jLxUgghhBANmATlwma83J14eGgnbo8KZtGmI3y4fC/RbXy5J16LbzMnsorPc65IZ7HxTtWJl0F0CYw2r/kd7B6Ii71MvBRCCCHErUWCcmFzIUEO3DPCm62HMtifvp9Xtv2AnVsRJozA5YmXLTxD6R4cd2nNb41MvBRCCCFEoyFBuag3BpMRXVHmxZHvSxMvzxWmk3/lxMtANyj1JDfdGw+VD3fFRNJLq5WJl0IIIYRo1CQoF7VOURQulOVe3vGyMJ1zRToyr5x4qbYnyC2QDj5aQq6YfFkx8fL/27vz+CjLc33g1zt7Jpnss2Tfk8nCkrAkiIAIIlYpiFCoAirKsS49LqfnuLW2tadqPVaxVnsQ9CciHgVktRZZBRFI2ANkg5CVkMkkIftKMr8/JhmIBJlAkvdNcn3/4ZP3nZncycfHufLM89zP6bxKfLY9B59tsiAzuh3zp0TBx0Mj5o9FRERE1GcYyummdG68tAfwC1dsvGxyPMZH4wV/NxNG+sZ3dD8xXXfjZXyYN15dPBbfphXi6/35OJlXgRm3hOLOscFQyGX98aMRERER9RuGcnJKu63dsfHyyhnwim42Xo42JiLAzQR/15vbeKlUyHDPLaFIiTfi/3acwVd7zuGHk6VYMC0acaHevfWjEREREYmOfco7sE/5ZbUtdZdnvju6n9hPvLy88dKo1Xfp9+3v6gdvjWefbrxMzy3H59vPoKyqEWNjDZh3exS8dOo++34kHVIdK0RSw7FC5Bz2KSdJaW1rRWlD2eV13x1LT67ceKlTuSHA1Q8TAsY51n6btAYoRdh4OTzCF7EhXvjmYCH+eaAAJ3IrMOvWMEwZFcglLURERDSgMZQPATabDZVNVSipv9zv+1obL+O8Y+xLTzoCuE7V/V9zYlEq5Jh5axjGxRvx+Y4z+HLXWew7eQEL7ohGTLCX2OURERER3RCG8kGm8VITLtR3znzbA3j3Gy/9MFKfAH/XzhMvfQbUiZcGLy2enjMcx8+U4/MdZ/CXz49hXLwJv7g9Eh6uKrHLIyIiIuoRUUN5S0sL3n33XWzatAk1NTUwm8149tlnMW7cuB69zpIlS7B3714sWrQIL7/8ch9VKy1t7W2wNlY4lpx0rgGvaLroeIxGrkGAm8mx8TLAzQ9+ria4KAZHa0FBEJAYrUdcmDe+3p+PramFOH7WinsnhGNyUgDkMi5pISIiooFB1FD+wgsvYNu2bVi0aBFCQkKwYcMGLFmyBKtWrUJiYqJTr/Hdd9/h8OHDfVxp70orPYrNuVtR1VwFT7Unfh4xHWNNSdd8fJeNl3WlOF9/AaVXbLyUCTIYtHqEugfjFv9kR+eTvt54KRVqpRz3TYrA+GF+WL0tG5/vOIN96Rew4M4YRAZ4iF0eERER0XWJ1n0lPT0dc+fOxYsvvoiHHnoIANDc3Ix77rkHBoMBq1evvu5rtLS0YMaMGZgxYwbee++9m5op76/uK2mlR/F51ldobW91XFPKlLjffB8S9cNQ2lB2edNlRwCvbalzPLZz4+WVB+6ItfFSimw2Gw5nW/HFzjO4WNuMW4f7Yc5tEXDXcknLQMaOEkTO4Vghcg67r1xh69atUCqVmDt3ruOaWq3GnDlz8M4776CsrAwGg+EnX+PTTz9FU1MTHnnkEbz33nt9XXKv2Jy7tUsgB4DW9lasylyDVZlrHBsvlR0bL+N9zAhwle7GS6kRBAFjzAYMC/fG5h/ysf1QEY7lWHHfpAhMHOEPmWzwf3JAREREA49ooTwzMxNhYWFwdXXtcn348OGw2WzIzMz8yVButVrxwQcf4JVXXoGLy40dTiOGi81V3V5vt7VjeugU+wy4qwl6rS9kAtdE3yiNSoFfTI7E+AQTPtuWg0+/zcb36SVYMC0GYX7uYpdHRERE1IVoodxqtcJoNF51Xa/XAwDKysp+8vlvv/02wsLCMHPmzF6p51ofJfQ2X603yhsqu72+OHlOv9QwlOj1OoyINWHPsfP4ePMp/PenhzE9JRQLfxYLHZe0DCh6vU7sEogGBI4VIudIbayIFsqbmpqgVF69Dlqttp/Q2NzcfM3npqenY+PGjVi1alWvbWTsrzXld4dO63ZN+d2h07gOsA/FB3ngT48kY9O+PHx7sADfHz+PubdFYPxwP8iGwGbYgY7rZImcw7FC5BwprikXbX2ERqNBa2vrVdc7w3hnOP8xm82GP//5z5g2bRpGjx7dpzX2hbGmJNxvvg9eak8IALzUnrjffN9Pdl+h3qHVKPDLqVF45aHRMPlo8f/+lYU3PjuKQgvfwIiIiEhcos2U6/X6bpeoWK1WALjmevLt27cjPT0dzz77LIqLi7vcq6urQ3FxMXx9faHRSLcX91hTEsaakjijIZJgow4vPJCE/SdLsfa7s/jjJ4dwe1Ig7p0QDq2G52kRERFR/xMtgZjNZqxatQr19fVdNnueOHHCcb87JSUlaG9vx4MPPnjVvfXr12P9+vVYvnw5Jk6c2DeF06AgEwTcOtwPidG+WL/3HHYdKcahrDLMmxyJlHjjkOjvTkRERNIhWiifPn06Pv74Y6xdu9bRp7ylpQXr169HUlKSYxNoSUkJGhsbERERAQC4/fbbERgYeNXrPfnkk5g8eTLmzJmD+Pj4fvs5aGBz1SixcFoMJgz3w6pvc7D86wzsOVGCBdOiEahn+0kiIiLqH6KF8hEjRmD69Ol46623YLVaERwcjA0bNqCkpASvv/6643HPP/880tLSkJ2dDQAIDg5GcHBwt68ZFBSEqVOn9kv9NLiEmtzx8qJR+P5ECdZ9l4s/fHwId4wJxM/Hh8FFzSUtRERE1LdETRtvvvkmli5dik2bNqG6uhoxMTH48MMPMWrUKDHLoiFKJgiYNDIASdF6fLUnF9+mFSE1w4L5U6IwxmzgkhYiIiLqM4LNZuv7PoADQH+1RLwSN3pKW+75aqzalo1CSx3iQr3wwB3R8PNxvf4TqddxrBA5h2OFyDlSbIl4w6G8vLwcp06dQnV1Nbp7iVmzZt3Iy4qGoZy6095uw+5j57F+7zm0tLZhenIw7hkXCrVKLnZpQwrHCpFzOFaInCPFUN7j5Svt7e344x//iHXr1qG9vf2ajxtooZyoOzKZgCmjAjHabMC63WfxzwMFOHi6FPOnRCMp2pdLWoiIiKhX9PjwoI8++ghffvkl7r77brzxxhuw2Wz4j//4D7zyyisICQlBQkICPv74476olUg0Hq4qPHJPHF54IAkuagXe33ASS9emw3KxQezSiIiIaBDocSjfuHEjJkyYgDfffNPRCzw+Ph6//OUvsX79ely8eBGnT5/u9UKJpCA6yBO/f3gM5t8eiTPFVfjdijRs/N6+tIWIiIjoRvU4lBcVFWHChAn2J8vsT7906RIAQKvVYvbs2Vi7dm0vlkgkLXKZDNPGBuPPS1IwKkaPzT/k47crUnHibLnYpREREdEA1eNQrtFooFDYl6JrtVoIgoCKigrHfb1ej9LS0t6rkEiivHRqPPbzePzn/JFQKmR4d1063vsqHeVVjWKXRkRERANMj0O5v78/ioqKAABKpRLBwcH4/vvvHff3798PHx+f3quQSOJiQ73xx8VjMfe2CJzOr8RvV6Riy/58tF669kZoIiIioiv1uPtKSkoKtm/fjueffx4AMHPmTPztb39DWVkZAODw4cNYvHhx71ZJJHEKuQx3pYQgOc6IL3aewYa957D/5AU8MC0aCWH8I5WIiIh+mvwPf/jDH3ryhOjoaCQkJMDPzw9yuRxJSUmoqanB/v37cfHiRcycORO/+c1vHEtcBorGxhb09zFKrq5qNDS09O83pT7lolZgTKwREf7uOHmuAjsOF+O8tQ4RAR5wUQ+sMSElHCtEzuFYIXKOWGNFEARotaru7/FETzseHkS9rfVSO7amFuDrAwWQCQJ+Pj4Ud4wJgkLe41VjQx7HCpFzOFaInCPFw4OYDoj6iFIhw4zxYfjzo8mIDfHC2u9y8fuP05BZcFHs0oiIiEhirvt5+qFDh27ohceMGXNDzyMabHw9XfDvc4bj+NlyfL49B//zf8eQHGfEvNsj4emmFrs8IiIikoDrhvKFCxfe0FHimZmZN1QQ0WA1MtIXcSFe+OZgAb45WIgTZ8sxa0I4powKgFzGD62IiIiGsuuG8tdff73L1zabDZ999hny8vIwY8YMREZGAgDOnj2Lr7/+GqGhoViwYEHfVEs0wKmUcsyaEI5xCSas3p6DL3aewb70EiyYFoPoIE+xyyMiIiKRXDeU33vvvV2+XrlyJSorK7F161YYjcYu95544gnMmzcP9fX1vVsl0SBj9NLi2bkjcDSnHP+3MwdvrD6K8QkmzJkcCQ/X7ndlExER0eDV48/MV69ejXnz5l0VyAHAZDJh3rx5+Oyzz3qlOKLBTBAEjIrR48+PpuBnKSE4mGHBSx8exM4jxf3eCYiIiIjE1eNQfuHCBbi4uFzzvlarxYULF26qKKKhRK2SY85tEXj1kbEINemwensO/rTyMHJLqsUujYiIiPpJj0N5YGAgNm/ejObm5qvuNTc3Y+PGjQgICOiV4oiGEj8fV/xm/kj8amY8quub8edPj+CTf2WirrFV7NKIiIioj/X4RE+VSoU1a9Zg586dEAQB9fX1KC4uxt69e/G73/0OZ86cwbPPPov4+Pg+Krlv8ERPkgJBEBCgd8PEEf5oa2/Hd8dKsOf4ebhqFAg26m6oE9JgwLFC5ByOFSLnDJoTPT/55BO8++67aGxsdIQEm80GjUaDp59+Gg8//PDNVSwCnuhJUlRsrcNn23KQU1SFMD93LLwzGqEmd7HL6nccK0TO4Vghco4UT/S8oVAOALW1tdi3bx+KiooAAEFBQRg/fjzc3QdmYGAoJ6my2Ww4cLoUa3adRW1DK25LCsDsieFw1SjFLq3fcKwQOYdjhcg5Ugzl122JeKX6+no8/vjjmDFjBubOnYu77rqrVwokomsTBAG3JPhhZKQvNnyfh11Hi3E4qwxzb4vELcNMkA3RJS1ERESDSY82erq6uuLkyZN9VQsR/QStRokH7ojG7x8aA4OXCz7+JhNvrD6KorI6sUsjIiKim9Tj7iuxsbE4d+5cX9RCRE4INurw4oJRePguM0orGvDH/3cI/7fjDBqbL4ldGhEREd2gHofyX//611izZg0OHjzYF/UQkRNkgoAJI/zx2r+lYOJIf+w4XISXPjyIg6dLcYPbRIiIiEhEPVpTDgCbN2+Gv78/Hn74YZjNZoSGhkKj0XR5jCAIeO2113qtSCLqnpuLEovujMGE4X5Y9W02PtySgb0nSvDAtBgE+LqKXR4RERE5qcfdV8xm8/VfVBCQmZl5w0WJgd1XaKBrb7dhz4kSrN+Ti6aWNtwxJgg/Hx8KjarHf3tLDscKkXM4VoicM+C7rwBAVlbWTRdERL1PJhMwOTEAo2L0WPddLramFiI1w4JfTonCqBj9kD14iIiIaCDo8ZpyIpI2d60Ki38Wi5cWjIKbixIfbDyFt9ecQGllg9ilERER0TXccChvaGjA/v37sXnzZpSXl/dmTUTUCyIDPfDKQ6Nx/9QonCupxisfpWL93lw0t7aJXRoRERH9yA2F8s8//xwTJ07E4sWL8fzzz+PMmTMAgIqKCgwbNgxr1qzp1SKJ6MbIZTJMHR2E15akYIzZgK/3F+C3y1NxLMfKLi1EREQS0uNQ/u233+LVV19FcnIy/vu//7vLG7uPjw8mTJiAHTt29GqRRHRzPNzUWDIjHs/fnwiNSo731p/Eu+vSUVbVKHZpREREhBsI5R999BGSk5Px/vvvY8qUKVfdT0hIcMycE5G0xAR74fcPj8EvJkciu6gKv12eik378tB6iUtaiIiIxNTjUJ6Tk4M77rjjmvf1ej0qKipuqigi6jsKuQzTk4Px2pIUJEX7YtO+PPxuRRrSczluiYiIxNLjUC6TydDe3n7N+2VlZXBxcbmpooio73np1PjVzAT8x/yRkMkELF17Au99lY7yai5pISIi6m89DuVmsxn79u3r9l57ezu2bt2KYcOG3XRhRNQ/4kO98eojY3HfpHCczq/Eb5en4p8H8nGp7dp/fBMREVHv6nEoX7BgAfbu3YulS5eiuroaAGCz2XDu3Dk8/fTTOHv2LBYuXNjrhRJR31HIZbh7XCj+/GgKEsJ98NWec3jlozSczq8UuzQiIqIhQbDdQF+0d955B8uWLXMsZZHJZLDZbLDZbHjqqafw1FNP9UWtfaqiog7t7f3bIo7HIZNUpedW4PPtOSirasQYswHzp0TBS6cWrR6OFSLncKwQOUessSKTCfDxcev2Xo9CeWVlJYqKiuDl5YW6ujps3rwZ586dg81mQ0hICGbOnDlgl64wlBN11XqpDf86WIh/HiyATCZg5vgwTB0dCIW8/w8C5lghcg7HCpFzpBjKFc68QHt7O/7whz9g3bp1jr7kI0eOxPvvvw9vb+/eq5SIJEOpkOPnt4YhJcGEz7fnYM3us/jh5AUsmBaNmGAvscsjIiIaVJya8vrss8+wZs0a+Pr64o477kB0dDSOHTuGV155pa/rIyKRGTxd8MzcEfj1fcPQ1NKGv3x+DB9uOY3qumaxSyMiIho0nJop37hxIyIiIvDll1/Czc0+5f7b3/4WGzZsQE1NDdzd3fu0SCISX2KUHnGh3vjngQJsTS3AibPlmDUhHLcnBUAu6/8lLURERIOJU++keXl5uPfeex2BHLB3YWlra0N+fn5f1UZEEqNWyjF7YjhefSQZ4f4e+L8dZ/DqJ4dxtrha7NKIiIgGNKdCeWNjIwwGQ5drnV83NDT0flVEJGkmby2e+8UIPDErAXWNrXjtsyP4+J+ZqGloEbs0IiKiAcmp5SsAIAhCt1/fQEdFIhoEBEHAaLMBCeHe2PJDPrYdKsLRHCvumxSOSSMDIJMJ138RIiIiAtCDUL5nzx6Ul5c7vm5sbIQgCNi6dSuysrK6PFYQBDz00EO9ViQRSZdGpcDcyZG4ZZgfVm/LxqptOfg+/QIW3hmDMD/uNyEiInKGU33KzWZzz15UEJCZmXnDRYmBfcqJbp7NZkNqpgVf7jqLmroWTBrpj9mTIuDmoryp1+VYIXIOxwqRcwZsn/JPP/20VwsiosFJEASkxJkwIsIXm/blYcfhYhzOtmLObRG4dbgfZAKXtBAREXWnRyd6DmacKSfqfUVldfhsWzbOFFcjIsAdC+6IQYhJ1+PX4Vghcg7HCpFzpDhTzubCRNRnggxueOGBJDxydyzKLjbi1ZWHsHpbDhqaWsUujYiISFKc3uhJRHQjBEHA+GF+SIzyxfq957DrWDEOZVnsm0MTTFd1diIiIhqKRJ0pb2lpwf/8z//g1ltvxfDhw/GLX/wCBw4cuO7zNm/ejEWLFmH8+PFISEjA7bffjhdffBHnz5/vh6qJ6EZoNUosmBaDVx4cA19PF3z0z0z8ZfVRFJfViV0aERGR6ERdU/7cc89h27ZtWLRoEUJCQrBhwwacOnUKq1atQmJi4jWf9+abb8JqtcJsNsPDwwMlJSVYs2YN2trasHnzZuj1+h7XwjXlRP2n3WbDvvQLWPddLhqaLmHq6EDMvDUMLuruP7zjWCFyDscKkXOkuKZctFCenp6OuXPn4sUXX3T0NG9ubsY999wDg8GA1atX9+j1Tp8+jdmzZ+O//uu/8Mgjj/S4HoZyov5X19iKdd/l4vsTJXB3U2H+7VEYG2u4akkLxwqRczhWiJwjxVAu2vKVrVu3QqlUYu7cuY5rarUac+bMwZEjR1BWVtaj1/P39wcA1NTU9GqdRNR33FyUeOguM15aNAqermos23wab31xHCXl9WKXRkRE1K9E2+iZmZmJsLAwuLq6drk+fPhw2Gw2ZGZmwmAw/ORrVFVVoa2tDSUlJXj//fcBAOPGjeuzmomob0T4e+B3D47Gd8fPY/2ec/j9x2mYNjYIJi8tNv+Qh8qaZni7qzF7UgTGxZvELpeIiKjXiRbKrVYrjEbjVdc714M7M1N+5513oqqqCgDg6emJV155BSkpKTdUz7U+Suhren3PezYTDVbz7nTHnbeE45N/nsa/DhZ2uVdR04xPt2bDXafBbaOCRKqQSPr4vkLkHKmNFdFCeVNTE5TKq4/eVqvVAOzry6/n73//OxoaGpCXl4fNmzejvv7GP/LmmnIi6XhgShQOnS5FTUPXfubNrW345OvTiA/2FKkyImnj+wqRc6S4ply0UK7RaNDaevUBIp1hvDOc/5QxY8YAACZNmoQpU6ZgxowZ0Gq1WLBgQe8WS0T97seBvFNFTTOOny1HQpg3FHKef0ZERIODaO9oer2+2yUqVqsVAK67nvzHgoKCEB8fjy1btvRKfUQkLh/37v8wFwD8bV06nn1vH1ZuzUJWwcV+/5SLiIiot4k2U242m7Fq1SrU19d32ex54sQJx/2eampqQmNjY6/VSETimT0pAiv/lYWWS+2OayqFDAvvjIGrixJpGRYcPG3BnuMl8HRTYWysEclxRoSadDwllIiIBhzRQvn06dPx8ccfY+3atY4+5S0tLVi/fj2SkpIcm0BLSkrQ2NiIiIgIx3MrKyvh7e3d5fVOnTqFrKws/OxnP+u3n4GI+k5nl5X1e3K77b4yMtIXzS1tOJFbjoOnLdh5pBjbDhXB4OWC5I6A7u/r+lPfgoiISDJEPdHz6aefxs6dO/Hggw8iODjYcaLnypUrMWrUKADAwoULkZaWhuzsbMfzRowYgbvuugvR0dHQarU4e/YsvvrqKyiVSnz55ZcICwvrcS3c6EkkXc6MlfqmVhzJtiI1w4Kswouw2YAggxuS44wYG2uAr4dLP1VLJB6+rxA5hxs9f+TNN9/E0qVLsWnTJlRXVyMmJgYffvihI5Bfy/33348DBw5gx44daGpqgl6vx/Tp0/HEE08gKIit0oiGIleNEhNH+GPiCH9U1zUjLasMaRkWrPsuF+u+y0VkgAeS44wYYzbA3VUldrlERERdiDpTLiWcKSeSrpsZK2VVjUjLsCA104Lz1nrIBAGxoV5IjjUiKVoPrUbUuQmiXsX3FSLnSHGmnKG8A0M5kXT11lgpttYhNcOC1AwLyquboJDLMDzCB8lxRoyI8IFKKe+FaonEw/cVIudIMZRzioiIhoxAvRsCJ7lh9sRwnCupQWqGBYeyynA0xwq1So6kKF8kx5kQF+rFHuhERNSvGMqJaMgRBAERAR6ICPDA/ClRyCq8iNQMC45kW3HgtAVuLkqMNhuQHGtAVJAnZGyxSEREfYyhnIiGNJlMQFyoN+JCvbFgWgxO5VUgNcOC/Scv4Ltj5+GlU2NsrAEpcSYEG93YA52IiPoEQzkRUQelQobEKD0So/RoarmE42fKkZphwY7Dxfg2rQhGby2SYw1IjjPCz4c90ImIqPcwlBMRdUOjUiAl3oSUeBPqGltxJLsMqRkWbPkhH5t/yEew0d4DPTnWCG93jdjlEhHRAMfuKx3YfYVIuqQ0Vi7WNuNQpr3FYt4Fe01RgR5IiTNilNkAdy17oJN4pDRWiKRMit1XGMo7MJQTSZdUx4rlYkNHD/QylJTbe6DHhV3uge6i5oeR1L+kOlaIpIahXMIYyomkS+pjxWazodha7+iBXlHTBKXC3gM9Jc6I4RE+UCrYA536ntTHCpFUSDGUcxqHiOgmCYKAIIMbggxuuG9SOHLPd/ZAt7dZdFHLkRSlR3KcEbGhXpDL2AOdiIi6YignIupFgiAgMtADkYEemD81ElkFVfYe6Dll+OFUKXRaew/0lDgjIgI82AOdiIgAMJQTEfUZuUyG+DBvxId5Y+Gd0UjPrURqpgX70i9g99Hz8HFXY2ysEclxRgQZ2AOdiGgoYygnIuoHSoUco2L0GBWjR2NzRw/0TAu2HSrCv1IL4eejRXJHQDd6a8Uul4iI+hlDORFRP3NRKzAuwYRxCSbUNrTgSLYVBzMs2LQvDxv35SHEpENKnBFjY43w0qnFLpeIiPoBu690YPcVIukaKmOlsqYJaZllSM20oKC0FgKA6CBPJMcZMdpsgJuLUuwSSeKGylghullS7L7CUN6BoZxIuobiWCmttPdAP5hhQWllA+QyAfFh3kiOMyIxyhcaFT/opKsNxbHZxnghAAAfnklEQVRCdCOkGMr5f3UiIgkyeWvx81vDMGN8KAotdUjNtCAt04L0LRVQKWQYEemL5DgjhoX7QKlgi0UiooGOoZyISMIEQUCISYcQkw5zbovA2eJqpGZacCizDIeyyuCiVmBUtL0HujnEkz3QiYgGKIZyIqIBQiYIiA7yRHSQJ345JQqZBReRmmHB4ewy7Dt5Ae5aJcaYjUiONyLC350tFomIBhCGciKiAUghl2FYuA+GhfugpbUN6bkVSM20YM+JEuw8WgxfD42jB3qg3pUBnYhI4hjKiYgGOJVSjtFmA0abDWhsvoSjOVakZlqwNbUQ3xwsgL+vK5JjDUiOM8LgxR7oRERSxFBORDSIuKgVGD/MD+OH+aGmoQWHs8qQmmHBhu/zsOH7PIT5uSM5zoixsQZ4urEHOhGRVLAlYge2RCSSLo6Vm1dR3YS0LAtSMywotNRBABATbO+BPiqGPdAHC44VIudIsSUiQ3kHhnIi6eJY6V0XKuqRmmEP6JaLjZDLBCSEeSM53ojESD3UKrnYJdIN4lghco4UQzmXrxARDTF+Pq6YNSEcM28NQ4GlFqkZFqRlluFEbgVUShlGXtEDXSFni0Uiov7AUE5ENEQJgoBQkztCTe6YOzkSZ4qqkJpZhsNZZUjLLINWrcCoGD1S4oyICfaCTMYOLkREfYWhnIiIIBMExAR7ISbYC/dPjUJGfqV9Bj2rDN+nX4CHmwpjzPYOLuF+7IFORNTbGMqJiKgLhVyG4RG+GB7hi+bOHugZFnx37Dx2HC6G3tPeAz0lzogAffdrI4mIqGcYyomI6JrUSjnGmA0YYzagoakVR3KsSMuw4JuDBfjngQIE6l07Wiwaofd0EbtcIqIBi91XOrD7CpF0caxIT3X95R7oZ89XAwAi/N0xNs6IsWYDPNgDXRQcK0TOkWL3FYbyDgzlRNLFsSJt5VWNSMsqw8HTFhRb6yAIgDnYCylxRoyK0UOrYQ/0/sKxQuQchnIJYygnki6OlYHjfLm9B3pahgVlVY1QyAUMC/dBcpwRIyJ9oVayB3pf4lghco4UQznXlBMRUa8J8HXF7InhuHdCGPJL7T3QUzMtOHamHGqlHIlR9h7o8WHe7IFORHQFhnIiIup1giAgzM8dYX7u+MXkSGQXVSE1w4Ij2WU4mGGBq0aB0WYDkmONiA72hIwtFoloiGMoJyKiPiWTCYgN8UJsiBcWTIvGqbxKpGVYcPC0BXuOl8DTTYWxsUYkxxkRatKxBzoRDUkM5URE1G8UchlGRvpiZKQvmlvacCK3HAdPW7DzSDG2HSqCwcsFyR0B3d/XVexyiYj6DUM5ERGJQq2SY2ysvcd5fVMrjmRbkZphwdcH8rFlfz6CDG4dPdAN8PVgD3QiGtzYfaUDu68QSRfHytBSXdeMtKwypGVYkFtSAwCIDPBAcpwRY8wGuLuqRK5QujhWiJwjxe4rDOUdGMqJpItjZegqq2pEWkcHl/PWesgEAbGhXkiONSIpWg+thh/4Xoljhcg5DOUSxlBOJF0cKwQAxdY6e4vFDAvKq5ugkMswPKKjB3qED1Tsgc6xQuQkKYZyTjEQEdGAEKh3Q+AkN8yeGI5zJTVIzbDgUFYZjuZYoVHJkRilR3KcEXGhXuyBTkQDDkM5ERENKIIgICLAAxEBHpg/JQpZhRc7eqBbceB0KdxclB090A2ICmIPdCIaGBjKiYhowJLJBMSFeiMu1BsLpsXgVF4FUjMs2H/yAr47dh5eOjXGxhqQEmdCsNGNPdCJSLIYyomIaFBQKmRIjNIjMUqPppZLOH6mHKkZFuw4XIxv04pg9NYiOdaA5Dgj/HzYA52IpIWhnIiIBh2NSoGUeBNS4k2oa2zFkewypGZYsOWHfGz+IR/BRnsP9ORYI7zdNWKXS0TE7iud2H2FSLo4Vqi3XKxtxqFMe4vFvAv2/6aiA+090EeZDXDXDuwe6BwrRM6RYvcVhvIODOVE0sWxQn3BcrGhowd6GUrK7T3Q48Iu90B3UQ+8D5M5Voicw1AuYQzlRNLFsUJ9yWazodha7+iBXlHTBKXC3gM9Jc6I4RE+UCoGRg90jhUi50gxlA+8aQAiIqJeJAgCggxuCDK44b5J4cg939kD3d5m0UUtR1JHD/TYUC/IZeyBTkS9j6GciIiogyAIiAz0QGSgB+ZPjURWQZW9B3pOGX44VQqd1t4DPSXOiIgAD/ZAJ6JeI2oob2lpwbvvvotNmzahpqYGZrMZzz77LMaNG/eTz9u2bRu++eYbpKeno6KiAn5+fpg8eTKeeOIJ6HS6fqqeiIgGM7lMhvgwb8SHeWPhndFIz61EaqYF+9IvYPfR8/BxV2NsrBHJcUYEGdgDnYhujqhryp977jls27YNixYtQkhICDZs2IBTp05h1apVSExMvObzkpOTYTAYMHXqVPj7+yM7OxtffPEFQkND8dVXX0GtVve4Fq4pJ5IujhWSksbmjh7omRaczqtEW7sNfj5aJHcEdKO3VrTaOFaInCPFNeWihfL09HTMnTsXL774Ih566CEAQHNzM+655x4YDAasXr36ms9NTU1FcnJyl2sbN27E888/j9dffx2zZ8/ucT0M5UTSxbFCUlXb0IIj2VYczLDgTFEVbABCTDqkxBkxNtYIL13PJ4luBscKkXOkGMpFW76ydetWKJVKzJ0713FNrVZjzpw5eOedd1BWVgaDwdDtc38cyAFg6tSpAIDc3Ny+KZiIiOhHdFoVbksMwG2JAaisaUJaZhlSMy34ctdZrNl1FtFBnkiOM2K02QA3F6XY5RKRhIkWyjMzMxEWFgZX165HHQ8fPhw2mw2ZmZnXDOXdKS8vBwB4eXn1ap1ERETO8HbXYHpyMKYnB6O00t4D/WCGBZ9+m43V23MQH+aN5DgjEqN8oVGxzwIRdSXa/xWsViuMRuNV1/V6PQCgrKysR6+3fPlyyOVyTJs2rVfqIyIiulEmby1+fmsYZowPRaGlDqmZFqRlWpC+pQIqhQwjIn2RHGfEsHAfKBVssUhEIobypqYmKJVXf5TXuUmzubnZ6dfasmUL1q1bh8ceewzBwcE3VM+11vf0Nb2e3WKInMGxQgOVweCO0cP88Xi7DZn5ldh7rBj7TpTgUFYZXDUKjBvmj0lJARgWqYdcdvMdXDhWiJwjtbEiWijXaDRobW296npnGHe2g8rhw4fx8ssv47bbbsPTTz99w/VwoyeRdHGs0GBh0KkwZ2I4Zo0PRWbBRaRmWLDvxHnsOFQId1cVxpgNSI4zIsLf/YZaLHKsEDmHGz2voNfru12iYrVaAcCp9eRZWVl4/PHHERMTg3feeQdy+cA4BpmIiIY2hVyGYeE+GBbug5bWNqTnViA104I9x0uw80gxfD00jh7ogXpX9kAnGgJEC+VmsxmrVq1CfX19l82eJ06ccNz/KYWFhXj00Ufh7e2NZcuWQasVry8sERHRjVIp5RhtNmC02YDG5ks4mmNFaqYFW1ML8c3BAvj7uiI51j6DbvDiex3RYCXa7pLp06ejtbUVa9eudVxraWnB+vXrkZSU5NgEWlJSclWbQ6vVisWLF0MQBHz00Ufw9vbu19qJiIj6gotagfHD/PDcL0bi7V+Px4Jp0XDVKLDh+zy8sOwg/rTyMLYdKkJVnfP7rohoYBD1RM+nn34aO3fuxIMPPojg4GDHiZ4rV67EqFGjAAALFy5EWloasrOzHc+bOXMmsrKy8OijjyI6OrrLawYHB//kaaDXwjXlRNLFsUJDXUV1E9KyLEjNsKDQUgcBQEywvQf6qBgDTp6rwPo9uaisaYa3uxqzJ0VgXLxJ7LKJJEuKa8pFDeXNzc1YunQptmzZgurqasTExOC5557DLbfc4nhMd6E8Jibmmq9577334o033uhxLQzlRNLFsUJ02YWKeqRm2AO65WIjBAAQgCvfzVUKGR68y8xgTnQNDOUSxlBOJF0cK0RXs9lsKLDU4s3Pj6Gppe2q+1qNAs/MHYEggxvUSjZCILqSFEM5jxQjIiIagARBQKjJvdtADgANTZfw2qojkAkC/Hy1CDXqEGLSIdTkbg/qKgZ1IilhKCciIhrAfNzVqKi5euOnp5saC6ZFo6C0FgWWWpzMq8QPp0oBAIIA+Pm4IsSoQ6jJHtaDjW7QqBgLiMTC0UdERDSAzZ4UgZX/ykLLpXbHNZVChrmTI5AUrUdStB6AfblLVV0L8ktr7EG9tBYZBZU4cLojqAMw+Wjts+nGzqCug4uaUYGoP3CkERERDWCdmzmv131FEAR46dTw0umRGKV3XK+qa0Z+R0gvKK1FdmEVDp622J8DwOCttc+md8yqBxt10GoYH4h6Gzd6duBGTyLp4lghck5vjZXq+hYUlNY4wnp+aS0u1l5eImPwcnEse+mcVddqlDf9fYn6Czd6EhERkeR5uKowPMIXwyN8Hddq6ltQYKl1BPXc89VIyyxz3Dd4uiDYdHmNeohRBzcXBnUiZzGUExER0XW5u6owLNwHw8J9HNdqG+xBvXM2Pf9CDQ5nXQ7qvh6ajo4vlzu/MKgTdY+hnIiIiG6ITqtCQpgPEsIuB/W6xtYuQb2gtAZHsq2O+z7uGvva9CvCurtWJUb5RJLCUE5ERES9xs1FifhQb8SHejuu1Te1orC0FvlXhPUjOZeDure7GiGOPuo6hJjc4eHKoE5DC0M5ERER9SlXjRKxod6IvSKoNzS1osBS5+ijnl9ai2Nnyh33vXTqyx1fOsK6p5tajPKJ+gVDOREREfU7rUaJ2BAvxIZ4Oa41Nl9CYedsese/J86Wo7M3moebytHtpXONuqebCoIgiPNDEPUihnIiIiKSBBe1AjHBXogJ7hrUi8rqLvdSt9Qi/VwFOhs6u7uquvRRDzHp4KVTM6jTgMNQTkRERJLlolYgOsgT0UGejmvNLW0oLLMveelcq37yiqCu0yovr083uiPUpIO3O4M6SRtDOREREQ0oapUcUYGeiAq8Iqi3tqGorK5jI2kNCkrr8E1eIdo7krqby5VB3f6vj4eGQZ0kg6GciIiIBjy1Uo7IAA9EBng4rrW0tqHIWufo+FJYWoutqYVo6zjB21Wj6LI+PcSkg55BnUTCUE5ERESDkkopR4S/ByL8Lwf11kttKLbWO3qo55fWYltakSOoa9VXBnX7vwZPFwZ16nMM5URERDRkKBVyhPm5I8zPHUAAAKD1UjvOl1/eTJpfWosdh4twqc0e1F3UCoQY3brMqhu8XCBjUKdexFBOREREQ5pSIUOoyR2hJnfHtUtt7ThvrXf0UC8orcHOI+dxqa0dAOCiliPYoOsyq2701jKo0w1jKCciIiL6EYVc5gjcE0fYr11qa0dJeX2XPuq7j51H6yV7UFer5AgxuDkOOwoxucPPWwuZjEGdro+hnIiIiMgJCrkMwUYdgo06TOi41tbejpLyBnsP9dJa5FtqsPd4CXZ0BnWlHEFGty591P18tJDLZOL9ICRJDOVEREREN0gukyHI4IYggxtuHe4HwB7UL1RcGdRr8X16CXYesQd1lUKGIKMbQo3uCDa5IdTkDn9fBvWhjqGciIiIqBfJZTIE6t0QqHfD+GH2oN7ebsOFygYUdPRQLyitwb5TF9B8tA2AfV17kMG+mTTUaJ9R9/d1hULOoD5UMJQTERER9TGZTECArysCfF1xS4L9WrvNBktlg6PrS0FpLQ6cKsXuo+cB2JfLBBlcEWJydxx6FKBnUB+sGMqJiIiIRCATBPj5uMLPxxXj4k0A7EG97GJjx6mk9qCemmHBd8c6g7qAAL2bY316qEmHAF83KBUM6gMdQzkRERGRRMgEASZvLUzeWqTEXQ7q1qpGRw/1gtJaHMosw57jJQAAuUxAgN7V0fEl1KRDoN4VSoVczB+FeoihnIiIiEjCZIIAo5cWRi8txsYaAQA2mw3W6qaOoG6fVT+SbcXeExcA2IO6v69rl5NJg/RuUCkZ1KWKoZyIiIhogBEEAQZPFxg8XTDGbABgD+oV1U322fSOQ4+OnynHvnR7UJcJAvx9tY5TSUNMOgQZ3KBmUJcEhnIiIiKiQUAQBPh6usDX0wWjrwjqlTXNHUG9BvmltUjPrcAPJ0s7ngP7jLrx8hr1YIMOahWDen9jKCciIiIapARBgI+HBj4eGoyK0QOwB/WLtc2X16hbanEqrxL7T10O6n4+rggxujnWqAcb3aBRMTb2Jf52iYiIiIYQQRDg7a6Bt7sGidGXg3pVXUuXNeoZBRdx4LTF/hwAJh/70pfO00mDjTq4qBklewt/k0RERERDnCAI8NKp4aVTY2SUr+N6VZ196Uthx6x6dmEVDnYEdQAwemsdPdQ7A7tWw3h5I/hbIyIiIqJuebqpMTJSjZGRl4N6dX1Lx8mk9qB+prgKqRmXg7rBy6VrUDfp4KpRilH+gMJQTkRERERO83BVYXiEL4ZHXA7qNfUtjo4vhaW1yD1fg7TMMsd9vaemy8mkISYd3FwY1K/EUE5EREREN8XdVYVh4T4YFu7juFbbYA/qnTPq+RdqcDjrclD39dB06aMeYtRBp1WJUb4kMJQTERERUa/TaVVICPNBQtjloF7X2NolqBd2HHrUycddjZCOHuqds+rurkMjqDOUExEREVG/cHNRIj7UG/Gh3o5r9U2t9o2kV4T1ozmXg7qXTu2YTbf/6w6PQRjUGcqJiIiISDSuGiViQ70Re0VQb2i6hEJLbZfTSY+dKXfc93RTOU4l7Qzrnm5qMcrvNQzlRERERCQpWo0C5hAvmEO8HNcam+1BveCKWfUTZ8th67jv4arqskY91OQOTzcVBEFwvMaB06VYvycXlTXN8HZXY/akCIyLN/XzT9c9hnIiIiIikjwXtQIxwV6ICb4c1JtaLqHQUtfldNKT5ypg60jq7q4qR7eX5pZL+O54CVovtQMAKmqasfJfWQAgiWDOUE5EREREA5JGpUB0kCeigzwd15pb2lBUVuc4mTTfUotTeZeD+pVaLrVj/Z5chnIiIiIiot6kVskRGeiByEAPx7Xm1jY8/tc93T6+oqa5v0r7STKxCyAiIiIi6ktqpRw+7t1vBL3W9f7GUE5EREREg97sSRFQKbpGX5VChtmTIkSqqCsuXyEiIiKiQa9z3Ti7rxARERERiWhcvAnj4k3Q63WwWmvFLqcLLl8hIiIiIhIZQzkRERERkcgYyomIiIiIRMZQTkREREQkMoZyIiIiIiKRMZQTEREREYmMoZyIiIiISGQM5UREREREImMoJyIiIiISGU/07CCTCUPq+xINNBwrRM7hWCFyjhhj5ae+p2Cz2Wz9WAsREREREf0Il68QEREREYmMoZyIiIiISGQM5UREREREImMoJyIiIiISGUM5EREREZHIGMqJiIiIiETGUE5EREREJDKGciIiIiIikTGUExERERGJjKGciIiIiEhkCrELGGrKysrw6aef4sSJEzh16hQaGhrw6aefIjk5WezSiCQjPT0dGzZsQGpqKkpKSuDp6YnExEQ888wzCAkJEbs8Isk4efIk/vd//xcZGRmoqKiATqeD2WzGk08+iaSkJLHLI5K05cuX46233oLZbMamTZvELoehvL/l5eVh+fLlCAkJQUxMDI4dOyZ2SUSSs2LFChw9ehTTp09HTEwMrFYrVq9ejVmzZmHdunWIiIgQu0QiSSgqKkJbWxvmzp0LvV6P2tpabNmyBQsWLMDy5csxfvx4sUskkiSr1Yp//OMf0Gq1YpfiINhsNpvYRQwldXV1aG1thZeXF3bs2IEnn3ySM+VEP3L06FEkJCRApVI5ruXn52PGjBm4++678cYbb4hYHZG0NTY2YurUqUhISMCyZcvELodIkl544QWUlJTAZrOhpqZGEjPlXFPez9zc3ODl5SV2GUSSlpSU1CWQA0BoaCiioqKQm5srUlVEA4OLiwu8vb1RU1MjdilEkpSeno7NmzfjxRdfFLuULhjKiWhAsNlsKC8v5x+1RN2oq6tDZWUlzp07h7fffhs5OTkYN26c2GURSY7NZsOf/vQnzJo1C7GxsWKX0wXXlBPRgLB582ZYLBY8++yzYpdCJDkvvfQSvv32WwCAUqnE/Pnz8atf/UrkqoikZ+PGjTh79izef/99sUu5CkM5EUlebm4uXn31VYwaNQozZ84UuxwiyXnyyScxb948lJaWYtOmTWhpaUFra+tVy8CIhrK6ujr89a9/xb/927/BYDCIXc5VuHyFiCTNarXiscceg4eHB959913IZPzfFtGPxcTEYPz48bjvvvvw0Ucf4fTp05JbL0sktn/84x9QKpV4+OGHxS6lW3x3IyLJqq2txZIlS1BbW4sVK1ZAr9eLXRKR5CmVSkyZMgXbtm1DU1OT2OUQSUJZWRlWrlyJ+++/H+Xl5SguLkZxcTGam5vR2tqK4uJiVFdXi1ojl68QkSQ1NzfjV7/6FfLz8/HJJ58gPDxc7JKIBoympibYbDbU19dDo9GIXQ6R6CoqKtDa2oq33noLb7311lX3p0yZgiVLluA3v/mNCNXZMZQTkeS0tbXhmWeewfHjx/HBBx9g5MiRYpdEJEmVlZXw9vbucq2urg7ffvst/Pz84OPjI1JlRNISGBjY7ebOpUuXoqGhAS+99BJCQ0P7v7ArMJSL4IMPPgAAR7/lTZs24ciRI3B3d8eCBQvELI1IEt544w3s2rULkydPRlVVVZdDHVxdXTF16lQRqyOSjmeeeQZqtRqJiYnQ6/W4cOEC1q9fj9LSUrz99ttil0ckGTqdrtv3jpUrV0Iul0vifYUneoogJiam2+sBAQHYtWtXP1dDJD0LFy5EWlpat/c4ToguW7duHTZt2oSzZ8+ipqYGOp0OI0eOxOLFizF27FixyyOSvIULF0rmRE+GciIiIiIikbH7ChERERGRyBjKiYiIiIhExlBORERERCQyhnIiIiIiIpExlBMRERERiYyhnIiIiIhIZAzlRESDXFtbGz766CNs3bpV7FKIiOgaGMqJiAa51157DRs3buRhMkREEsZQTkQ0iJWWlsLLywsrV66Et7e32OUQEdE18ERPIiIiIiKRKcQugIiIeldqaioWLVp0zftyuRwZGRn9WBEREV0PQzkR0SB1zz33YOLEiVddl8m4cpGISGoYyomIBqm4uDjMnDlT7DKIiMgJDOVERENUcXExpkyZgqeeegphYWFYtmwZ8vPz4ePjg/vuuw+PP/44FIqubxNZWVl47733cPjwYTQ0NCAoKAj33nsvFi9eDLlc3uWxVqsVy5Ytw+7du2GxWKDT6WA2m/Hoo49i/PjxAID09HR8/vnnOHbsGEpLSyGTyRATE4NHHnkEd9xxR7/9LoiIxMZQTkQ0SDU2NqKysvKq6yqVCm5ubo6vd+3ahaKiIjzwwAPw9fXFrl278Pe//x0lJSV4/fXXHY87efIkFi5cCIVC4Xjs7t278dZbbyErKwt//etfHY8tLi7GL3/5S1RUVGDmzJlISEhAY2MjTpw4gf379ztC+fbt23Hu3DlMnz4dAQEBqKqqwoYNG/DUU0/hrbfewowZM/rwN0REJB3svkJENMhcb6PnbbfdhmXLljlmymUyGdatW4f4+HgAgM1mw1NPPYUdO3bgyy+/xMiRIwEA8+fPR3p6OtavXw+z2ex47DPPPIOtW7fik08+wbhx4wAAS5Yswd69e7FixQpMmDChy/dvb293rGtvaGiAVqvtcr+xsRGzZs2CXC7HN9980zu/FCIiieNMORHRIDVv3jxMnz79qus/7ld+yy23OAI5AAiCgEcffRQ7duzA9u3bMXLkSFRUVODYsWO44447HIG887GPP/44tm7diu3bt2PcuHGoqqrC999/jwkTJlwVyIGuG02vDOSNjY1oamqCzWZDSkoKvvjiC9TV1XWZ1SciGqwYyomIBqmQkBDccsst131cRETEVdciIyMBAEVFRQDsy1GuvH6l8PBwyGQyx2MLCwths9kQFxd33e9dUVGBpUuXYufOnaioqLjqfk1NDUM5EQ0JDOVERCQKm82GxYsXIzc3F4sWLUJCQgJ0Oh3kcjm++uorfP3112hvbxe7TCKifsFQTkQ0xOXm5l517ezZswCAoKAgAEBgYGCX61c6d+4c2tvbHY8NDg6GIAjIzMz8ye+bnZ2NrKwsPPnkk/j3f//3LvfWrl3b8x+EiGgA4wkSRERD3P79+3H69GnH1zabDStWrAAATJ06FQDg4+ODxMRE7N69Gzk5OV0e++GHHwKAo4Whp6cnJk6ciL1792L//v1Xfb/O/gKda8t/3G8gJycH27dv760fj4hoQOBMORHRIJWRkYFNmzZ1e68zbAOA2WzGgw8+iAceeAB6vR47d+7E/v37MXPmTCQmJjoe9/LLL2PhwoV44IEHcP/990Ov12P37t3Yt28f7rnnHkfnFQD43e9+h4yMDCxZsgSzZs1CfHw8mpubceLECQQEBOA///M/ERERgaioKKxYsQJNTU0ICwtDXl4evvzyS0RHR3f5Q4GIaLBjS0QiokHmei0RAWDbtm2Qy+VXHR6Ul5cHHx8fzJ49G0888QSUSmWX52VlZeFvf/tbl8ODZs+e3e3hQRaLBe+//z727t2L8vJyuLu7w2w2Y8mSJY4Af/78efzlL39BWloaGhsbERUVhcceewxZWVn4+9//jp07dzqWzhARDWYM5UREQ9SVJ3r++te/FrscIqIhjWvKiYiIiIhExlBORERERCQyhnIiIiIiIpFxTTkRERERkcg4U05EREREJDKGciIiIiIikTGUExERERGJjKGciIiIiEhkDOVERERERCJjKCciIiIiEtn/B2BwXjF9JEfoAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjyahGzSUThc"
      },
      "source": [
        "## Desempenho no conjunto de teste \n",
        "\n",
        "Agora, carregaremos o conjunto de dados *holdout* e preparamos as entradas, como fizemos com o conjunto de treinamento. \n",
        "\n",
        "Em seguida, avaliaremos as previs√µes usando o [coeficiente de correla√ß√£o de Matthew](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html), m√©trica usada para avaliar o desempenho no CoLA. Com essa m√©trica, +1 √© a melhor pontua√ß√£o e -1 √© a pior pontua√ß√£o. Dessa forma, podemos ver nosso desempenho em rela√ß√£o aos modelos de √∫ltima gera√ß√£o para essa tarefa espec√≠fica.\n",
        "\n",
        "### Prepara√ß√£o de dados \n",
        "\n",
        "Precisaremos aplicar todas as mesmas etapas que fizemos para os dados de treinamento para preparar nosso conjunto de dados de teste.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4GZU-RGUThc",
        "outputId": "5a14d864-b278-4fa4-b24a-e8a120bbed00"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carrega o dataset em um dataframe pandas\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\n",
        "# Imprime o n√∫mero de frases\n",
        "print('N√∫mero de frases de teste: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Cria as listas de frases e r√≥tulos\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "\n",
        "# Tokeniza todas as senten√ßas e mapeia os tokens em seus IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# Para cada frase\n",
        "for sent in sentences:\n",
        "    # `encode_plus` vai:\n",
        "    #   (1) Tokenizar a frase\n",
        "    #   (2) Adicionar o token `[CLS]` no in√≠cio\n",
        "    #   (3) Adicionar o token `[SEP]` no final.\n",
        "    #   (4) Mapear tokens aos seus IDs.\n",
        "    #   (5) Preencher ou truncar a frase at√© `max_length`\n",
        "    #   (6) Criar m√°scara de aten√ß√£o para os tokens [PAD].\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Senten√ßa a ser codificada\n",
        "                        add_special_tokens = True, # Adiciona '[CLS]' e '[SEP]'\n",
        "                        max_length = 64,           # Preenche & trunca todas as senten√ßas\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Constr√≥i m√°scara de aten√ß√£o\n",
        "                        return_tensors = 'pt',     # Retorna tensores pytorch.\n",
        "                   )\n",
        "    \n",
        "    # Adiciona a senten√ßa codificada na lista\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # E sua m√°scara de aten√ß√£o (simplesmente diferencia preenchimento (PAD) de n√£o-pad).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Converte as listas em tensores.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Seta o batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Cria o DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N√∫mero de frases de teste: 516\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeqtTUuWUThc"
      },
      "source": [
        "### Avalia√ß√£o no conjunto de teste ###\n",
        "\n",
        "Com o conjunto de teste preparado, podemos aplicar nosso modelo ajustado para gerar previs√µes no conjunto de teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOO9WqCkUThc",
        "outputId": "ef6f533a-a422-4a03-daad-7e0ca2c5e1bf"
      },
      "source": [
        "# Predi√ß√£o no conjunto de teste\n",
        "\n",
        "print('Predi√ß√£o de r√≥tulos para {:,} frases de teste...'.format(len(input_ids)))\n",
        "\n",
        "# coloca o modele em modo de avalia√ß√£o\n",
        "model.eval()\n",
        "\n",
        "# Vari√°veis de rastreamento\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predi√ß√£o \n",
        "for batch in prediction_dataloader:\n",
        "  # Adiciona o batch na GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Retira as entradas do dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Informa o modelo para n√£o computar gradientes, salvando mem√≥ria e acelerando a predi√ß√£o \n",
        "  with torch.no_grad():\n",
        "      # Passo Forward, calcula as predi√ß√µes logit\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  # Move as logits e r√≥tulos para CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Armazen predi√ß√µes e r√≥tulos verdadeiros\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('FIM.')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predi√ß√£o de r√≥tulos para 516 frases de teste...\n",
            "FIM.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Diwh1xgqUThc"
      },
      "source": [
        "A precis√£o no *benchmark* CoLA √© medida usando o ‚Äúcoeficiente de correla√ß√£o de Matthews‚Äù (MCC).\n",
        "\n",
        "Usamos MCC aqui porque as classes s√£o desequilibradas:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ss3ueMk5UThd",
        "outputId": "6042df38-2cb2-4919-feba-f259fee43221"
      },
      "source": [
        "print('Inst√¢ncias positivas: %d de %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Inst√¢ncias positivas: 354 de 516 (68.60%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP02zqm4UThd",
        "outputId": "60feb3eb-64bf-4c36-9cbe-fe1647079ba9"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Avaliando cada batch de teste usando MCC\n",
        "print('Calculando MCC para cada batch...')\n",
        "\n",
        "# Para cada batch\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # As predi√ß√µes para este batch s√£o a 2a. coluna do ndarray (uma coluna para \"0\" e outra para \"1\")\n",
        "  # Pega o r√≥tulo com o maior valor e transforma em uma lista de 0s e 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  \n",
        "  # Calcula e armazena o coef para este batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculando MCC para cada batch...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNnOntTjUThd"
      },
      "source": [
        "A pontua√ß√£o final ser√° baseada em todo o conjunto de teste, mas vamos dar uma olhada nas pontua√ß√µes dos lotes individuais para ter uma no√ß√£o da variabilidade da m√©trica entre os lotes.\n",
        "\n",
        "Cada lote cont√©m 32 senten√ßas, exceto o √∫ltimo lote que cont√©m apenas (516% 32) = 4 senten√ßas de teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "2FdSg9ZVUThd",
        "outputId": "b0a57176-f9c9-45c0-fd91-db93b2bee650"
      },
      "source": [
        "# Cria um barplot mostrando o MCC para cada batch dos nossos exemplos de teste.\n",
        "ax = sns.barplot(x=list(range(len(matthews_set))), y=matthews_set, ci=None)\n",
        "\n",
        "plt.title('MCC por Batch')\n",
        "plt.ylabel('MCC Score (-1 a +1)')\n",
        "plt.xlabel('Batch #')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIprQ7dIUThe"
      },
      "source": [
        "Agora combinaremos os resultados de todos os lotes e calcularemos nossa pontua√ß√£o final no MCC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgg1F-lCUThe",
        "outputId": "14162985-fa56-4e49-df3e-8e3aea3bb5a4"
      },
      "source": [
        "# Combina os resultados para todos os batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# Para cada exemplo, pega o r√≥tulo (0 ou 1) com maior score\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combina os r√≥tulos para cada batch em uma √∫nica lista.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calcula o MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total MCC: 0.556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G2SYdJSUThe"
      },
      "source": [
        "Legal! Em cerca de meia hora e sem fazer nenhum ajuste de hiperpar√¢metro (ajustando a taxa de aprendizagem, √©pocas, tamanho do lote, propriedades ADAM, etc.), obtivemos uma boa pontua√ß√£o."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wbeNbEZUThe"
      },
      "source": [
        "Nota: Para maximizar a pontua√ß√£o, devemos remover o ‚Äúconjunto de valida√ß√£o‚Äù (que usamos para ajudar a determinar em quantas √©pocas treinar) e treinar em todo o conjunto de treinamento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AddBAXzdUThe"
      },
      "source": [
        "A biblioteca documenta a precis√£o esperada para este *benchmark* aqui como **49.23** ([ver tabela de classifica√ß√£o oficial](https://gluebenchmark.com/leaderboard/submission/zlssuBTm5XRs0aSKbFYGVIVdvbj1/-LhijX9VVmvJcvzKymxy)).\n",
        "\n",
        "## Conclus√£o \n",
        "\n",
        "Com um modelo BERT pr√©-treinado, podemos criar de forma r√°pida e eficaz um modelo de alta qualidade com o m√≠nimo de esfor√ßo e tempo de treinamento usando a interface *Pytorch*, independentemente da tarefa PLN espec√≠fica em que estamos interessados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2vM0vX2UThe"
      },
      "source": [
        "### Salvar e carregar o modelo ajustado \n",
        "\n",
        "A pr√≥xima c√©lula grava o modelo e o tokenizador no disco."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2clVnjW1UThf",
        "outputId": "2a2a0a6a-57e7-4d00-db46-1b5504de01f1"
      },
      "source": [
        "import os\n",
        "\n",
        "# Boa-pr√°tica: usar os nomes padr√£o dos modelos, para fazer load usando from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Criar diret√≥rio de sa√≠da se necess√°rio\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Savando modelo em %s\" % output_dir)\n",
        "\n",
        "# Salva um modelo treinado, sua configura√ß√£o e tokenizador com `save_pretrained()`.\n",
        "# Eles podem ser carregados com `from_pretrained()`\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Cuida do treinamento paralelo/distribu√≠do\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "# Boa-pr√°tica: salve os argumentos de treinamento junto com o modelo\n",
        "# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Savando modelo em ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/vocab.txt',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcE3HTvOUThf"
      },
      "source": [
        "Vamos verificar os tamanhos dos arquivos, por curiosidade.\n",
        "\n",
        "No Colab:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g47ZXApIUThf",
        "outputId": "9454ad83-5111-412a-b3f7-129e48b5a5fb"
      },
      "source": [
        "!ls -l --block-size=K ./model_save/\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 427996K\n",
            "-rw-r--r-- 1 root root      1K Dec 11 19:55 config.json\n",
            "-rw-r--r-- 1 root root 427753K Dec 11 19:55 pytorch_model.bin\n",
            "-rw-r--r-- 1 root root      1K Dec 11 19:55 special_tokens_map.json\n",
            "-rw-r--r-- 1 root root      1K Dec 11 19:55 tokenizer_config.json\n",
            "-rw-r--r-- 1 root root    227K Dec 11 19:55 vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-dC-d_SUThf"
      },
      "source": [
        "O maior arquivo √© o peso do modelo, em torno de 418 megabytes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF7Jc6cEUThf",
        "outputId": "870cc3c9-b3c1-481e-8a05-36ffd43cddb3"
      },
      "source": [
        "!ls -l --block-size=M ./model_save/pytorch_model.bin\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 418M Dec 11 19:55 ./model_save/pytorch_model.bin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fONYFF4TUThf"
      },
      "source": [
        "Para salvar seu modelo nas sess√µes do **Colab Notebook**, baixe-o em sua m√°quina local ou, de prefer√™ncia, copie-o para o Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdXVUpBLY2tz"
      },
      "source": [
        "# Montando Google Drive nesta inst√¢ncia\r\n",
        "from google.colab import drive\r\n",
        "\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNzuRt1OYM_b"
      },
      "source": [
        "# Copia os arquivos do modelo num diret√≥rio do Google Drive.\r\n",
        "!cp -r ./model_save/ \"./drive/Shared drives/PLN/BERT Fine-Tuning/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8UjaufMUThg"
      },
      "source": [
        "As fun√ß√µes a seguir carregar√£o o modelo de volta do disco.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUQgKi5OUThg"
      },
      "source": [
        "# Carrega um modelo treinado e seu vocabul√°rio\n",
        "model = model_class.from_pretrained(output_dir)\n",
        "tokenizer = tokenizer_class.from_pretrained(output_dir)\n",
        "\n",
        "# Copia o modelo na GPU\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
